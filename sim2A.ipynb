{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Little bit of theory:\n",
    "\n",
    "**Transfer entropy**: the mutual information between $Y_{pres}$ and $X_{past}$, conditioned on $Y_{past}$\n",
    "\n",
    "$$ TE(X\\rightarrow Y) = I(X_{past}; Y_{pres}|Y_{past}) $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ I(S=s,X_i) = \\sum_{x_i \\in X_i} p(x_i|s)\\,\\log\\frac{p(s|x_i)}{p(s)}$$\n",
    "\n",
    "is the specific information that the source $X_i$ carries about a specific outcome of the target variable $s\\in S$.\n",
    "\n",
    "**FIT**:\n",
    "\n",
    "$$ FIT = \\text{min}[SUI(S: X_{past}, Y_{pres} \\ Y_{past} ),\\, SUI(Y_{pres}: X_{past}, S\\ Y_{past})] $$\n",
    "\n",
    "where \n",
    "- $SUI(S: X_{past}, Y_{pres} \\ Y_{past} )$ is the information about $S$ that $X_{past}$ shares with $Y_{pres}$ and it's unique with respect to $Y_{past}$ and it's defined as the difference between the shared information that $X_{past}, Y_{pres}$ carry about $S$ and the shared information that $X_{past}, Y_{pres}$ and $Y_{past}$ carry about $S$\n",
    "- $SUI(Y_{pres}: X_{past}, S\\ Y_{past})$ is the information about $Y_{pres}$ that $X_{past}$ shares with $S$ and it's unique with respect to $Y_{past}$\n",
    "\n",
    "Moreover\n",
    "\n",
    "$$ SUI(S:X_1,X_2) = \\sum_{s\\in S} p(s) \\text{min}_{X_i \\in \\{ X_1, X_2\\} } I(S=s,X_i) $$\n",
    "\n",
    "is the shared information that $X_1$ and $X_2$ carry about $S$.\n",
    "\n",
    "**Sender activity**: 2D variable\n",
    "\n",
    "$$X(t)_{stim} = S(t)(1+N(0, \\sigma_{stim}))$$\n",
    "\n",
    "where $S(t)$ is a step function equal to the value of the stimulus $s \\in [1,4]$ during the time window $[200,250]\\,ms$.\n",
    "\n",
    "$$X(t)_{noise} = N(0,\\sigma)$$\n",
    "\n",
    "**Receiver activity**: 1D variable\n",
    "\n",
    "$$Y(t) = W_{stim}X_{stim}(t-\\delta) + W_{noise}X_{noise}(t-\\delta) + N(0,\\sigma)$$\n",
    "\n",
    "where the **delay** $\\delta$ is chosen randomly from a uniform distribution in $[40,60]\\,ms$ in step of $10\\,ms$, moreover $\\sigma = 2$ and $\\sigma_{stim} = \\sigma/5 = 0.4$.\n",
    "\n",
    "**Numerical computation of FIT**: discretization of neural activity into a number R of equipopulated bins and empirical computation of the occurence frequency of each binned response across all available trials.\n",
    "\n",
    "FIT/TE are computed at the first time instant in which $Y$ received information from $X$.\n",
    "\n",
    "Total of 50 simulation with 500 trials per stimulus each one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WHAT TO DO\n",
    "\n",
    "- **Fig. 2A**: evaluation of FIT and TE for each value of $W_{noise}$ and $W_{stim}$\n",
    "- **Fig. 2B**: FIT and TE as a function of time with $W_{stim}=0.5$ and $W_{noise}=1$ (FIT/TE values computed at all points and averaged over delays to obtain temporal profiles of transmitted information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from compute_FIT_TE import get_joint_prob_distr, compute_FIT_TE_DFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTrials_per_stim = 50      # number of trials for each simulation\n",
    "simReps = 1                # number of simulations\n",
    "nShuff = 10                 # number of permutations\n",
    "\n",
    "w_sig = np.linspace(0, 1, num=2)      # signal weights for Y computation\n",
    "w_noise = np.linspace(0, 1, num=2)    # noise weights for Y computation\n",
    "stdX_noise = 2                      # std of gaussian noise in X_noise\n",
    "stdY = 2                            # std of gaussian noise in Y\n",
    "ratio = 0.2                         # ratio between stdX_sig and stdX_noise\n",
    "stdX_sig = ratio * stdX_noise       # std of gaussian noise in X_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "simLen = 60                             # simulation length in units of 10 ms\n",
    "stimWin = [30, 35]                      # X stimulus encoding window in units of 10 ms\n",
    "delays = np.linspace(4, 6, num=3, dtype=int)\n",
    "n_binsS = 4                             # number of stimulus values\n",
    "n_binsX = 3\n",
    "n_binsY = 3\n",
    "eps = 1e-52                             # infinitesimal value\n",
    "\n",
    "nTrials = nTrials_per_stim * n_binsS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw random delay for each simulation repetition\n",
    "reps_delays = npr.choice(delays, simReps, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = np.full(shape=(simReps, len(w_sig), len(w_noise)), fill_value=np.nan)\n",
    "te = fit.copy()\n",
    "dfi = fit.copy()\n",
    "fitsh = np.full((simReps, len(w_sig), len(w_noise), nShuff), np.nan)\n",
    "dish = fitsh.copy()\n",
    "dfish = fitsh.copy()\n",
    "fitsh_cond = np.full((simReps, len(w_sig), len(w_noise), nShuff), np.nan)\n",
    "dish_cond = fitsh_cond.copy()\n",
    "dfish_cond = fitsh_cond.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils functions (here only for debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SUI(joint_prob_distr):\n",
    "\n",
    "    # get dimensions\n",
    "    dim_x_past = joint_prob_distr.shape[0]\n",
    "    dim_y_pres = joint_prob_distr.shape[1]\n",
    "    dim_y_past = joint_prob_distr.shape[2]\n",
    "    dim_s = joint_prob_distr.shape[3]\n",
    "\n",
    "    # initialize arrays\n",
    "    spec_surprise_x = np.zeros(dim_s)\n",
    "    spec_surprise_y = np.zeros(dim_s)\n",
    "    spec_surprise_y_past = np.zeros(dim_s)\n",
    "\n",
    "    # compute specific information provided by each source variable about s (target)\n",
    "    for s in range(dim_s):\n",
    "\n",
    "        # p(s)\n",
    "        ps = np.sum(joint_prob_distr[:, :, :, s]) \n",
    "\n",
    "        # info provided by x past\n",
    "        for x in range(dim_x_past):\n",
    "            psx = np.sum(joint_prob_distr[x, :, :, s]) / (np.sum(joint_prob_distr[x, :, :, :]) + np.finfo(float).eps)\n",
    "            pxs = np.sum(joint_prob_distr[x, :, :, s]) / (np.sum(joint_prob_distr[:, :, :, s]) + np.finfo(float).eps)\n",
    "\n",
    "            spec_surprise_x[s] += pxs * (np.log2(1/(ps + np.finfo(float).eps)) - np.log2(1/(psx + np.finfo(float).eps)))\n",
    "\n",
    "        # info provided by y\n",
    "        for y in range(dim_y_pres):\n",
    "            psy = np.sum(joint_prob_distr[:, y, :, s]) / (np.sum(joint_prob_distr[:, y, :, :]) + np.finfo(float).eps)\n",
    "            pys = np.sum(joint_prob_distr[:, y, :, s]) / (np.sum(joint_prob_distr[:, :, :, s]) + np.finfo(float).eps)\n",
    "            \n",
    "            spec_surprise_y[s] += pys * (np.log2(1/(ps + np.finfo(float).eps)) - np.log2(1/(psy + np.finfo(float).eps)))\n",
    "\n",
    "        # info provided by y past\n",
    "        for y in range(dim_y_past):\n",
    "            psy = np.sum(joint_prob_distr[:, :, y, s]) / (np.sum(joint_prob_distr[:, :, y, :]) + np.finfo(float).eps)\n",
    "            pys = np.sum(joint_prob_distr[:, :, y, s]) / (np.sum(joint_prob_distr[:, :, :, s]) + np.finfo(float).eps)\n",
    "            \n",
    "            spec_surprise_y_past[s] += pys * (np.log2(1/(ps + np.finfo(float).eps)) - np.log2(1/(psy + np.finfo(float).eps)))\n",
    "\n",
    "    # compute IMin\n",
    "\n",
    "    IMin_x_y_ypast = 0\n",
    "    IMin_x_y = 0\n",
    "\n",
    "    for s in range(dim_s):\n",
    "        IMin_x_y_ypast += np.sum(joint_prob_distr[:, :, :, s]) * min(spec_surprise_x[s], spec_surprise_y[s], spec_surprise_y_past[s])\n",
    "        IMin_x_y += np.sum(joint_prob_distr[:, :, :, s]) * min(spec_surprise_x[s], spec_surprise_y[s])\n",
    "\n",
    "    return IMin_x_y - IMin_x_y_ypast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SUI(joint_prob_distr):\n",
    "\n",
    "    # get dimensions\n",
    "    dim_x_past = joint_prob_distr.shape[0]\n",
    "    dim_y_pres = joint_prob_distr.shape[1]\n",
    "    dim_y_past = joint_prob_distr.shape[2]\n",
    "    dim_s = joint_prob_distr.shape[3]\n",
    "\n",
    "    # initialize arrays\n",
    "    spec_surprise_x = np.zeros(dim_s)\n",
    "    spec_surprise_y = np.zeros(dim_s)\n",
    "    spec_surprise_y_past = np.zeros(dim_s)\n",
    "\n",
    "    # compute specific information provided by each source variable about s (target)\n",
    "    for s in range(dim_s):\n",
    "\n",
    "        # p(s)\n",
    "        ps = np.sum(joint_prob_distr[:, :, :, s]) \n",
    "\n",
    "        # info provided by x past\n",
    "        for x in range(dim_x_past):\n",
    "            psx = np.sum(joint_prob_distr[x, :, :, s]) / (np.sum(joint_prob_distr[x, :, :, :]) + np.finfo(float).eps)\n",
    "            pxs = np.sum(joint_prob_distr[x, :, :, s]) / (np.sum(joint_prob_distr[:, :, :, s]) + np.finfo(float).eps)\n",
    "\n",
    "            spec_surprise_x[s] += pxs * (np.log2(1/(ps + np.finfo(float).eps)) - np.log2(1/(psx + np.finfo(float).eps)))\n",
    "\n",
    "        # info provided by y\n",
    "        for y in range(dim_y_pres):\n",
    "            psy = np.sum(joint_prob_distr[:, y, :, s]) / (np.sum(joint_prob_distr[:, y, :, :]) + np.finfo(float).eps)\n",
    "            pys = np.sum(joint_prob_distr[:, y, :, s]) / (np.sum(joint_prob_distr[:, :, :, s]) + np.finfo(float).eps)\n",
    "            \n",
    "            spec_surprise_y[s] += pys * (np.log2(1/(ps + np.finfo(float).eps)) - np.log2(1/(psy + np.finfo(float).eps)))\n",
    "\n",
    "        # info provided by y past\n",
    "        for y in range(dim_y_past):\n",
    "            psy = np.sum(joint_prob_distr[:, :, y, s]) / (np.sum(joint_prob_distr[:, :, y, :]) + np.finfo(float).eps)\n",
    "            pys = np.sum(joint_prob_distr[:, :, y, s]) / (np.sum(joint_prob_distr[:, :, :, s]) + np.finfo(float).eps)\n",
    "            \n",
    "            spec_surprise_y_past[s] += pys * (np.log2(1/(ps + np.finfo(float).eps)) - np.log2(1/(psy + np.finfo(float).eps)))\n",
    "\n",
    "    # compute IMin\n",
    "\n",
    "    IMin_x_y_ypast = 0\n",
    "    IMin_x_y = 0\n",
    "\n",
    "    for s in range(dim_s):\n",
    "        IMin_x_y_ypast += np.sum(joint_prob_distr[:, :, :, s]) * min(spec_surprise_x[s], spec_surprise_y[s], spec_surprise_y_past[s])\n",
    "        IMin_x_y += np.sum(joint_prob_distr[:, :, :, s]) * min(spec_surprise_x[s], spec_surprise_y[s])\n",
    "\n",
    "    return IMin_x_y - IMin_x_y_ypast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TE(joint_prob_distr):\n",
    "\n",
    "    p_ypast = np.sum(joint_prob_distr, axis=(0, 1, 3))\n",
    "    p_x_ypast = np.sum(joint_prob_distr, axis=(1, 3))\n",
    "    p_y_ypast = np.sum(joint_prob_distr, axis=(0, 3))\n",
    "    p_x_y_ypast = np.sum(joint_prob_distr, axis=3)\n",
    "    \n",
    "    def entropy(p):\n",
    "        p_nonzero = p[p > 0]  # Avoid log of zero\n",
    "        return - np.sum(p_nonzero * np.log2(p_nonzero))\n",
    "    \n",
    "    h_ypast = entropy(p_ypast)\n",
    "    h_x_ypast = entropy(p_x_ypast)\n",
    "    h_y_ypast = entropy(p_y_ypast)\n",
    "    h_x_y_ypast = entropy(p_x_y_ypast)\n",
    "    \n",
    "    return h_y_ypast - h_ypast - h_x_y_ypast + h_x_ypast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_DFI(joint_prob_distr):\n",
    "    \n",
    "    # marginal distributions\n",
    "    prob_ypast = np.sum(joint_prob_distr, axis=(0, 1, 3))\n",
    "    prob_x_ypast = np.sum(joint_prob_distr, axis=(1, 3))\n",
    "    prob_y_ypast = np.sum(joint_prob_distr, axis=(0, 3))\n",
    "    prob_ypast_s = np.sum(joint_prob_distr, axis=(0, 1))\n",
    "    prob_x_y_ypast = np.sum(joint_prob_distr, axis=3)\n",
    "    prob_y_ypast_s = np.sum(joint_prob_distr, axis=0)\n",
    "    prob_x_ypast_s = np.sum(joint_prob_distr, axis=1)\n",
    "    \n",
    "    def get_entropy(prob_dist):\n",
    "        prob_nonzero = prob_dist[prob_dist > 0]  # Filter out zero values\n",
    "        return -np.sum(prob_nonzero * np.log2(prob_nonzero))\n",
    "    \n",
    "    # entropies\n",
    "    h_ypast = get_entropy(prob_ypast)\n",
    "    h_x_ypast = get_entropy(prob_x_ypast)\n",
    "    h_y_ypast = get_entropy(prob_y_ypast)\n",
    "    h_ypast_s = get_entropy(prob_ypast_s)\n",
    "    h_x_y_ypast = get_entropy(prob_x_y_ypast)\n",
    "    h_y_ypast_s = get_entropy(prob_y_ypast_s)\n",
    "    h_x_ypast_s = get_entropy(prob_x_ypast_s)\n",
    "    h_x_y_ypast_s = get_entropy(joint_prob_distr)\n",
    "    \n",
    "    # compute DFI\n",
    "    dfi = h_y_ypast - h_ypast - h_x_y_ypast + h_x_ypast - h_y_ypast_s + h_ypast_s + h_x_y_ypast_s - h_x_ypast_s\n",
    "    \n",
    "    return dfi, h_ypast, h_x_ypast, h_y_ypast, h_ypast_s, h_x_y_ypast, h_y_ypast_s, h_x_ypast_s, h_x_y_ypast_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_joint_prob_distr(target, source_var1, source_var2, source_var3):\n",
    "\n",
    "    assert np.min(source_var1) > 0, \"Invalid values in source variable 1\"\n",
    "    assert np.min(source_var2) > 0, \"Invalid values in source variable 2\"\n",
    "    assert np.min(source_var3) > 0, \"Invalid values in source variable 3\"\n",
    "    assert np.min(target) > 0, \"Invalid values in target\"\n",
    "    \n",
    "    count = len(source_var1)\n",
    "\n",
    "    # compute probabilities from (multi-dim) histogram frequencies\n",
    "    result, _ = np.histogramdd(\n",
    "        np.vstack([source_var1, source_var2, source_var3, target]).T, \n",
    "        bins=[np.max(source_var1), np.max(source_var2), np.max(source_var3), np.max(target)]\n",
    "    )\n",
    "    \n",
    "    return result / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FIT_TE_DFI(feature, X, Y, hY, xtrap=20):\n",
    "    # Build the two four-variables probability distributions needed to compute FIT\n",
    "    pXYhYS = get_joint_prob_distr(feature, X, Y, hY)    # probability distribution for the PID with (Xp, Yp, Yt) as sources and S as target\n",
    "    pXShYY = get_joint_prob_distr(Y, X, feature, hY)    # probability distribution for the PID with (Xp, Yp, S) as sources and Yt as target\n",
    "\n",
    "    # Compute the two FIT atoms and FIT\n",
    "    sui_S = get_SUI(pXYhYS)\n",
    "    sui_Y = get_SUI(pXShYY)\n",
    "\n",
    "    fit = np.min([sui_S, sui_Y])\n",
    "\n",
    "    # Compute TE\n",
    "    te = compute_TE(pXYhYS)\n",
    "\n",
    "    # Compute DFI\n",
    "    dfi = compute_DFI(pXYhYS)\n",
    "\n",
    "    # Compute quadratic extrapolation bias correction for FIT and TE\n",
    "    fit_all = fit\n",
    "    te_all = te\n",
    "\n",
    "    FIT2 = np.zeros(xtrap)\n",
    "    FIT4 = np.zeros(xtrap)\n",
    "    TE2 = np.zeros(xtrap)\n",
    "    TE4 = np.zeros(xtrap)\n",
    "\n",
    "    for xIdx in range(xtrap):\n",
    "\n",
    "        numberOfTrials = len(X)\n",
    "\n",
    "        # Shuffled indexes in 0,ntrials range\n",
    "        rIdx = npr.choice(numberOfTrials, numberOfTrials, replace=False)\n",
    "        \n",
    "        # Divide the indexes in 2 and 4 parts\n",
    "        idx2 = np.array_split(rIdx, 2) \n",
    "        idx4 = np.array_split(rIdx, 4)\n",
    "        \n",
    "        # Stack all the sources in data, separate into 2 and 4 parts, and distinguish between s and y targets\n",
    "        data = np.stack(np.array([feature, X, Y, hY]),axis=1)\n",
    "        data2_s = np.stack(np.array([data[idx2[i]] for i in range(2)]), axis = 0)\n",
    "        data2_y = data2_s[:, :, [2, 1, 0, 3]]\n",
    "        data2_tot = np.stack(np.array([data2_s,data2_y]), axis=0)\n",
    "        \n",
    "        data4_s = np.stack(np.array([data[idx4[i]] for i in range(4)]), axis = 0)\n",
    "        data4_y = data4_s[:, :, [2, 1, 0, 3]]\n",
    "        data4_tot = np.stack(np.array([data4_s,data4_y]), axis=0)\n",
    "\n",
    "        # Compute Joint, SUI, FIT and TE for the 2 divided version\n",
    "        joint2 = [[\n",
    "            get_joint_prob_distr(*[data2_tot[ch,row, :, i] for i in range(4)])\n",
    "            for row in range(data2_tot.shape[1])]\n",
    "            for ch in range(data2_tot.shape[0])\n",
    "        ]\n",
    "        \n",
    "        SUI_2 = [[get_SUI(joint2[ch][i]) for i in range(2)] for ch in range(len(joint2))]\n",
    "\n",
    "        FIT2[xIdx] = np.mean(np.min(SUI_2, axis=0))\n",
    "        TE2[xIdx] = np.mean([compute_TE(joint2[0][i]) for i in range(2)])\n",
    "        \n",
    "        # Compute Joint, SUI, FIT and TE for the 4 divided version\n",
    "        joint4 = [[\n",
    "            get_joint_prob_distr(*[data4_tot[ch,row, :, i] for i in range(4)])\n",
    "            for row in range(data4_tot.shape[1])]\n",
    "            for ch in range(data4_tot.shape[0])\n",
    "        ]\n",
    "        \n",
    "        SUI_4 = [[get_SUI(joint4[ch][i]) for i in range(4)] for ch in range(len(joint4))]\n",
    "\n",
    "        FIT4[xIdx] = np.mean(np.min(SUI_4,axis=0))\n",
    "        TE4[xIdx] = np.mean([compute_TE(joint4[0][i]) for i in range(4)])\n",
    "\n",
    "    # Compute the linear and quadratic interpolations for FIT and TE\n",
    "\n",
    "    x = [1/len(idx2[0]), 1/len(idx4[0]), 1/len(rIdx)]\n",
    "    y = [np.mean(FIT4), np.mean(FIT2), fit_all]\n",
    "\n",
    "    p2 = np.polyfit(x, y, 2)\n",
    "    p1 = np.polyfit(x, y, 1) \n",
    "    FITQe = p2[2]\n",
    "    FITLe = p1[1]\n",
    "\n",
    "    y = [np.mean(TE4), np.mean(TE2), te_all]\n",
    "    \n",
    "    print('prima del polyfit')\n",
    "\n",
    "    p2 = np.polyfit(x, y, 2)\n",
    "    p1 = np.polyfit(x, y, 1) \n",
    "    TEQe = p2[2]\n",
    "    TELe = p1[1]\n",
    "\n",
    "    print('dopo del polyfit')\n",
    "         \n",
    "\n",
    "    return te, dfi, fit#, TEQe, TELe, FITQe, FITLe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation number:  0 \n",
      "\n",
      "prima del polyfit\n",
      "dopo del polyfit\n",
      "prima del polyfit\n",
      "dopo del polyfit\n",
      "prima del polyfit\n",
      "dopo del polyfit\n",
      "prima del polyfit\n",
      "dopo del polyfit\n"
     ]
    }
   ],
   "source": [
    "for simIdx in range(simReps):\n",
    "    print('Simulation number: ', simIdx, '\\n')\n",
    "    for sigIdx in range(len(w_sig)):\n",
    "        for noiseIdx in range(len(w_noise)):\n",
    "            # draw the stimulus value for each trial\n",
    "            S = npr.randint(1, n_binsS + 1, size=nTrials)\n",
    "\n",
    "            # simulate neural activity\n",
    "            X_noise = npr.normal(0, stdX_noise, size=(simLen, nTrials)) # Noise time series\n",
    "\n",
    "            X_signal = eps * npr.normal(0, stdX_noise, size=(simLen, nTrials)) # Infinitesimal signal to avoid binning \n",
    "\n",
    "            X_signal[stimWin[0]:stimWin[1],:] = np.tile(S, (stimWin[1]-stimWin[0], 1)) # Assigning Stimulus to Window\n",
    "\n",
    "            # Adding multiplicative noise (we changed the dimension from nTrials to (simLen, nTrials) to have a different error for each time step)\n",
    "            X_signal = X_signal * (1 + npr.normal(0, stdX_sig, size=(simLen, nTrials))) \n",
    "\n",
    "            # Time lagged single-trial input from the 2 dimensions of X and Y (we multpily everything by the weights, they mutiply only the stim/noise)\n",
    "            X2Ysig = w_sig[sigIdx] * np.vstack((eps * npr.normal(0, stdX_noise, size=(reps_delays[simIdx], nTrials)),\\\n",
    "                      X_signal[0:len(X_signal)-reps_delays[simIdx],:]))\n",
    "            X2Ynoise = w_noise[noiseIdx] * np.vstack((eps * npr.normal(0, stdX_noise, size=(reps_delays[simIdx], nTrials)),\\\n",
    "                      X_noise[0:len(X_signal)-reps_delays[simIdx],:]))\n",
    "\n",
    "            # Computing Y + gaussian noise\n",
    "            Y = X2Ysig + X2Ynoise + npr.normal(0,stdY,size=(simLen, nTrials))\n",
    "\n",
    "            # ??????\n",
    "            X = X_signal + X_noise\n",
    "\n",
    "            # First time point at which Y receives stim info from X\n",
    "            t = stimWin[0] + reps_delays[simIdx]\n",
    "            d = reps_delays[simIdx]\n",
    "\n",
    "            # Discretize Neural Activity\n",
    "            #_, bin_edges = pd.cut(X_noise[t-d,:], n_binsX, retbins=True)\n",
    "            #bX_noise = np.digitize(X_noise[t-d, :], bins=bin_edges, right=True)\n",
    "\n",
    "            #_, bin_edges = pd.cut(X_signal[t-d,:], n_binsX, retbins=True)\n",
    "            #bX_sig = np.digitize(X_signal[t-d,:], bins=bin_edges, right=True)\n",
    "\n",
    "            _, bin_edges = pd.cut(X[t-d,:], n_binsX, retbins=True)\n",
    "            bX = np.digitize(X[t-d,:], bins=bin_edges, right=True)\n",
    "\n",
    "            _, bin_edges = pd.cut(Y[t,:], n_binsY, retbins=True)\n",
    "            bYt = np.digitize(Y[t,:], bins=bin_edges, right=True)\n",
    "\n",
    "            _, bin_edges = pd.cut(Y[t-d,:], n_binsY, retbins=True)\n",
    "            bYpast = np.digitize(Y[t-d,:], bins=bin_edges, right=True)\n",
    "\n",
    "            #bX = (bX_sig - 1) * n_binsX + bX_noise\n",
    "\n",
    "            te, dfi, fit = compute_FIT_TE_DFI(S, bX, bYt, bYpast)\n",
    "\n",
    "\n",
    "            ######## SHUFFLING ########\n",
    "\n",
    "            #   XSh = np.empty_like(bX)\n",
    "   \n",
    "            #   for shIdx in range(nShuff):\n",
    "            #       for Ss in np.unique(S):\n",
    "            #           idx = (S == Ss)\n",
    "            #           tmpX = bX[idx]\n",
    "            #           rIdx = npr.choice(np.sum(idx), np.sum(idx), replace=False)\n",
    "            #           XSh[idx] = tmpX[rIdx]\n",
    "            #   \n",
    "            #   dish_cond, dfish_cond, fitsh_cond = compute_FIT_TE(S, XSh, bYt, bYpast)\n",
    "   \n",
    "            #   idx = npr.choice(nTrials, nTrials, replace=False)\n",
    "            #   Ssh = S[idx]\n",
    "            #   XSh = bX[idx]\n",
    "   \n",
    "            #   _, dfish, fitsh = compute_FIT_TE(Ssh, bX, bYt, bYpast)\n",
    "            #   dish = DI_infToolBox(XSh, bYt, bYpast, 'naive', 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laura",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
