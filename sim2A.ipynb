{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Little bit of theory:\n",
    "\n",
    "**Transfer entropy**: the mutual information between $Y_{pres}$ and $X_{past}$, conditioned on $Y_{past}$\n",
    "\n",
    "$$ TE(X\\rightarrow Y) = I(X_{past}; Y_{pres}|Y_{past}) $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ I(S=s,X_i) = \\sum_{x_i \\in X_i} p(x_i|s)\\,\\log\\frac{p(s|x_i)}{p(s)}$$\n",
    "\n",
    "is the specific information that the source $X_i$ carries about a specific outcome of the target variable $s\\in S$.\n",
    "\n",
    "**FIT**:\n",
    "\n",
    "$$ FIT = \\text{min}[SUI(S: X_{past}, Y_{pres} \\ Y_{past} ),\\, SUI(Y_{pres}: X_{past}, S\\ Y_{past})] $$\n",
    "\n",
    "where \n",
    "- $SUI(S: X_{past}, Y_{pres} \\ Y_{past} )$ is the information about $S$ that $X_{past}$ shares with $Y_{pres}$ and it's unique with respect to $Y_{past}$ and it's defined as the difference between the shared information that $X_{past}, Y_{pres}$ carry about $S$ and the shared information that $X_{past}, Y_{pres}$ and $Y_{past}$ carry about $S$\n",
    "- $SUI(Y_{pres}: X_{past}, S\\ Y_{past})$ is the information about $Y_{pres}$ that $X_{past}$ shares with $S$ and it's unique with respect to $Y_{past}$\n",
    "\n",
    "Moreover\n",
    "\n",
    "$$ SUI(S:X_1,X_2) = \\sum_{s\\in S} p(s) \\text{min}_{X_i \\in \\{ X_1, X_2\\} } I(S=s,X_i) $$\n",
    "\n",
    "is the shared information that $X_1$ and $X_2$ carry about $S$.\n",
    "\n",
    "**Sender activity**: 2D variable\n",
    "\n",
    "$$X(t)_{stim} = S(t)(1+N(0, \\sigma_{stim}))$$\n",
    "\n",
    "where $S(t)$ is a step function equal to the value of the stimulus $s \\in [1,4]$ during the time window $[200,250]\\,ms$.\n",
    "\n",
    "$$X(t)_{noise} = N(0,\\sigma)$$\n",
    "\n",
    "**Receiver activity**: 1D variable\n",
    "\n",
    "$$Y(t) = W_{stim}X_{stim}(t-\\delta) + W_{noise}X_{noise}(t-\\delta) + N(0,\\sigma)$$\n",
    "\n",
    "where the **delay** $\\delta$ is chosen randomly from a uniform distribution in $[40,60]\\,ms$ in step of $10\\,ms$, moreover $\\sigma = 2$ and $\\sigma_{stim} = \\sigma/5 = 0.4$.\n",
    "\n",
    "**Numerical computation of FIT**: discretization of neural activity into a number R of equipopulated bins and empirical computation of the occurence frequency of each binned response across all available trials.\n",
    "\n",
    "FIT/TE are computed at the first time instant in which $Y$ received information from $X$.\n",
    "\n",
    "Total of 50 simulation with 500 trials per stimulus each one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WHAT TO DO\n",
    "\n",
    "- **Fig. 2A**: evaluation of FIT and TE for each value of $W_{noise}$ and $W_{stim}$\n",
    "- **Fig. 2B**: FIT and TE as a function of time with $W_{stim}=0.5$ and $W_{noise}=1$ (FIT/TE values computed at all points and averaged over delays to obtain temporal profiles of transmitted information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files to save the simulation results\n",
    "file_2A = 'sim_file_2A.npz'\n",
    "file_2B = 'sim_file_2B.npz'\n",
    "\n",
    "sim2A_ready = False     # set to True if the simulation is ready\n",
    "sim2B_ready = False     # set to True if the simulation is ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTrials_per_stim = 500      # number of trials for each simulation\n",
    "simReps = 50                # number of simulations\n",
    "nShuff = 10                 # number of permutations\n",
    "\n",
    "# START MODIFICA\n",
    "w_sig = np.linspace(0, 1, num=11)      # signal weights for Y computation\n",
    "w_noise = np.linspace(0, 1, num=11)    # noise weights for Y computation\n",
    "# END MODIFICA\n",
    "\n",
    "stdX_noise = 2                      # std of gaussian noise in X_noise\n",
    "stdY = 2                            # std of gaussian noise in Y\n",
    "ratio = 0.2                         # ratio between stdX_sig and stdX_noise\n",
    "stdX_sig = ratio * stdX_noise       # std of gaussian noise in X_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "simLen = 60                             # simulation length in units of 10 ms\n",
    "stimWin = [30, 35]                      # X stimulus encoding window in units of 10 ms\n",
    "delays = np.linspace(4, 6, num=3, dtype=int)\n",
    "delay_max = 10                          # Maximum Computed Delay\n",
    "n_binsS = 4                             # number of stimulus values\n",
    "n_binsX = 3\n",
    "n_binsY = 3\n",
    "eps = 1e-52                             # infinitesimal value\n",
    "\n",
    "nTrials = nTrials_per_stim * n_binsS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw random delay for each simulation repetition\n",
    "reps_delays = npr.choice(delays, simReps, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START MODIFICA\n",
    "# A\n",
    "fit_A = np.full(shape=(simReps, len(w_sig), len(w_noise)), fill_value=np.nan)\n",
    "te_A = fit_A.copy()\n",
    "dfi_A = fit_A.copy()\n",
    "fitsh = np.full((simReps, len(w_sig), len(w_noise), nShuff), np.nan)\n",
    "dish = fitsh.copy()\n",
    "dfish = fitsh.copy()\n",
    "fitsh_cond = np.full((simReps, len(w_sig), len(w_noise), nShuff), np.nan)\n",
    "dish_cond = fitsh_cond.copy()\n",
    "dfish_cond = fitsh_cond.copy()\n",
    "\n",
    "# B\n",
    "S_B = np.full(shape=(simReps, simLen, nTrials), fill_value=np.nan)\n",
    "X_noise_B = S_B.copy()\n",
    "X_signal_B = S_B.copy()\n",
    "Y_B = S_B.copy()\n",
    "fit_B = np.full(shape=(simReps, simLen, delay_max), fill_value=np.nan)\n",
    "te_B = fit_B.copy()\n",
    "dfi_B = fit_B.copy()\n",
    "# END MODIFICA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils functions (here only for debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SUI(joint_prob_distr):\n",
    "\n",
    "    # get dimensions\n",
    "    dim_x_past = joint_prob_distr.shape[0]\n",
    "    dim_y_pres = joint_prob_distr.shape[1]\n",
    "    dim_y_past = joint_prob_distr.shape[2]\n",
    "    dim_s = joint_prob_distr.shape[3]\n",
    "\n",
    "    # initialize arrays\n",
    "    spec_surprise_x = np.zeros(dim_s)\n",
    "    spec_surprise_y = np.zeros(dim_s)\n",
    "    spec_surprise_y_past = np.zeros(dim_s)\n",
    "\n",
    "    # compute specific information provided by each source variable about s (target)\n",
    "    for s in range(dim_s):\n",
    "\n",
    "        # p(s)\n",
    "        ps = np.sum(joint_prob_distr[:, :, :, s]) \n",
    "\n",
    "        # info provided by x past\n",
    "        for x in range(dim_x_past):\n",
    "            psx = np.sum(joint_prob_distr[x, :, :, s]) / (np.sum(joint_prob_distr[x, :, :, :]) + np.finfo(float).eps)\n",
    "            pxs = np.sum(joint_prob_distr[x, :, :, s]) / (np.sum(joint_prob_distr[:, :, :, s]) + np.finfo(float).eps)\n",
    "\n",
    "            spec_surprise_x[s] += pxs * (np.log2(1/(ps + np.finfo(float).eps)) - np.log2(1/(psx + np.finfo(float).eps)))\n",
    "\n",
    "        # info provided by y\n",
    "        for y in range(dim_y_pres):\n",
    "            psy = np.sum(joint_prob_distr[:, y, :, s]) / (np.sum(joint_prob_distr[:, y, :, :]) + np.finfo(float).eps)\n",
    "            pys = np.sum(joint_prob_distr[:, y, :, s]) / (np.sum(joint_prob_distr[:, :, :, s]) + np.finfo(float).eps)\n",
    "            \n",
    "            spec_surprise_y[s] += pys * (np.log2(1/(ps + np.finfo(float).eps)) - np.log2(1/(psy + np.finfo(float).eps)))\n",
    "\n",
    "        # info provided by y past\n",
    "        for y in range(dim_y_past):\n",
    "            psy = np.sum(joint_prob_distr[:, :, y, s]) / (np.sum(joint_prob_distr[:, :, y, :]) + np.finfo(float).eps)\n",
    "            pys = np.sum(joint_prob_distr[:, :, y, s]) / (np.sum(joint_prob_distr[:, :, :, s]) + np.finfo(float).eps)\n",
    "            \n",
    "            spec_surprise_y_past[s] += pys * (np.log2(1/(ps + np.finfo(float).eps)) - np.log2(1/(psy + np.finfo(float).eps)))\n",
    "\n",
    "    # compute IMin\n",
    "\n",
    "    IMin_x_y_ypast = 0\n",
    "    IMin_x_y = 0\n",
    "\n",
    "    for s in range(dim_s):\n",
    "        IMin_x_y_ypast += np.sum(joint_prob_distr[:, :, :, s]) * min(spec_surprise_x[s], spec_surprise_y[s], spec_surprise_y_past[s])\n",
    "        IMin_x_y += np.sum(joint_prob_distr[:, :, :, s]) * min(spec_surprise_x[s], spec_surprise_y[s])\n",
    "\n",
    "    return IMin_x_y - IMin_x_y_ypast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SUI(joint_prob_distr):\n",
    "\n",
    "    # get dimensions\n",
    "    dim_x_past = joint_prob_distr.shape[0]\n",
    "    dim_y_pres = joint_prob_distr.shape[1]\n",
    "    dim_y_past = joint_prob_distr.shape[2]\n",
    "    dim_s = joint_prob_distr.shape[3]\n",
    "\n",
    "    # initialize arrays\n",
    "    spec_surprise_x = np.zeros(dim_s)\n",
    "    spec_surprise_y = np.zeros(dim_s)\n",
    "    spec_surprise_y_past = np.zeros(dim_s)\n",
    "\n",
    "    # compute specific information provided by each source variable about s (target)\n",
    "    for s in range(dim_s):\n",
    "\n",
    "        # p(s)\n",
    "        ps = np.sum(joint_prob_distr[:, :, :, s]) \n",
    "\n",
    "        # info provided by x past\n",
    "        for x in range(dim_x_past):\n",
    "            psx = np.sum(joint_prob_distr[x, :, :, s]) / (np.sum(joint_prob_distr[x, :, :, :]) + np.finfo(float).eps)\n",
    "            pxs = np.sum(joint_prob_distr[x, :, :, s]) / (np.sum(joint_prob_distr[:, :, :, s]) + np.finfo(float).eps)\n",
    "\n",
    "            spec_surprise_x[s] += pxs * (np.log2(1/(ps + np.finfo(float).eps)) - np.log2(1/(psx + np.finfo(float).eps)))\n",
    "\n",
    "        # info provided by y\n",
    "        for y in range(dim_y_pres):\n",
    "            psy = np.sum(joint_prob_distr[:, y, :, s]) / (np.sum(joint_prob_distr[:, y, :, :]) + np.finfo(float).eps)\n",
    "            pys = np.sum(joint_prob_distr[:, y, :, s]) / (np.sum(joint_prob_distr[:, :, :, s]) + np.finfo(float).eps)\n",
    "            \n",
    "            spec_surprise_y[s] += pys * (np.log2(1/(ps + np.finfo(float).eps)) - np.log2(1/(psy + np.finfo(float).eps)))\n",
    "\n",
    "        # info provided by y past\n",
    "        for y in range(dim_y_past):\n",
    "            psy = np.sum(joint_prob_distr[:, :, y, s]) / (np.sum(joint_prob_distr[:, :, y, :]) + np.finfo(float).eps)\n",
    "            pys = np.sum(joint_prob_distr[:, :, y, s]) / (np.sum(joint_prob_distr[:, :, :, s]) + np.finfo(float).eps)\n",
    "            \n",
    "            spec_surprise_y_past[s] += pys * (np.log2(1/(ps + np.finfo(float).eps)) - np.log2(1/(psy + np.finfo(float).eps)))\n",
    "\n",
    "    # compute IMin\n",
    "\n",
    "    IMin_x_y_ypast = 0\n",
    "    IMin_x_y = 0\n",
    "\n",
    "    for s in range(dim_s):\n",
    "        IMin_x_y_ypast += np.sum(joint_prob_distr[:, :, :, s]) * min(spec_surprise_x[s], spec_surprise_y[s], spec_surprise_y_past[s])\n",
    "        IMin_x_y += np.sum(joint_prob_distr[:, :, :, s]) * min(spec_surprise_x[s], spec_surprise_y[s])\n",
    "\n",
    "    return IMin_x_y - IMin_x_y_ypast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TE(joint_prob_distr):\n",
    "\n",
    "    p_ypast = np.sum(joint_prob_distr, axis=(0, 1, 3))\n",
    "    p_x_ypast = np.sum(joint_prob_distr, axis=(1, 3))\n",
    "    p_y_ypast = np.sum(joint_prob_distr, axis=(0, 3))\n",
    "    p_x_y_ypast = np.sum(joint_prob_distr, axis=3)\n",
    "    \n",
    "    def entropy(p):\n",
    "        p_nonzero = p[p > 0]  # Avoid log of zero\n",
    "        return - np.sum(p_nonzero * np.log2(p_nonzero))\n",
    "    \n",
    "    h_ypast = entropy(p_ypast)\n",
    "    h_x_ypast = entropy(p_x_ypast)\n",
    "    h_y_ypast = entropy(p_y_ypast)\n",
    "    h_x_y_ypast = entropy(p_x_y_ypast)\n",
    "    \n",
    "    return h_y_ypast - h_ypast - h_x_y_ypast + h_x_ypast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_DFI(joint_prob_distr):\n",
    "    \n",
    "    # marginal distributions\n",
    "    prob_ypast = np.sum(joint_prob_distr, axis=(0, 1, 3))\n",
    "    prob_x_ypast = np.sum(joint_prob_distr, axis=(1, 3))\n",
    "    prob_y_ypast = np.sum(joint_prob_distr, axis=(0, 3))\n",
    "    prob_ypast_s = np.sum(joint_prob_distr, axis=(0, 1))\n",
    "    prob_x_y_ypast = np.sum(joint_prob_distr, axis=3)\n",
    "    prob_y_ypast_s = np.sum(joint_prob_distr, axis=0)\n",
    "    prob_x_ypast_s = np.sum(joint_prob_distr, axis=1)\n",
    "    \n",
    "    def get_entropy(prob_dist):\n",
    "        prob_nonzero = prob_dist[prob_dist > 0]  # Filter out zero values\n",
    "        return -np.sum(prob_nonzero * np.log2(prob_nonzero))\n",
    "    \n",
    "    # entropies\n",
    "    h_ypast = get_entropy(prob_ypast)\n",
    "    h_x_ypast = get_entropy(prob_x_ypast)\n",
    "    h_y_ypast = get_entropy(prob_y_ypast)\n",
    "    h_ypast_s = get_entropy(prob_ypast_s)\n",
    "    h_x_y_ypast = get_entropy(prob_x_y_ypast)\n",
    "    h_y_ypast_s = get_entropy(prob_y_ypast_s)\n",
    "    h_x_ypast_s = get_entropy(prob_x_ypast_s)\n",
    "    h_x_y_ypast_s = get_entropy(joint_prob_distr)\n",
    "    \n",
    "    # compute DFI\n",
    "    dfi = h_y_ypast - h_ypast - h_x_y_ypast + h_x_ypast - h_y_ypast_s + h_ypast_s + h_x_y_ypast_s - h_x_ypast_s\n",
    "    \n",
    "    return dfi#, h_ypast, h_x_ypast, h_y_ypast, h_ypast_s, h_x_y_ypast, h_y_ypast_s, h_x_ypast_s, h_x_y_ypast_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_joint_prob_distr(target, source_var1, source_var2, source_var3):\n",
    "\n",
    "    assert np.min(source_var1) > 0, \"Invalid values in source variable 1\"\n",
    "    assert np.min(source_var2) > 0, \"Invalid values in source variable 2\"\n",
    "    assert np.min(source_var3) > 0, \"Invalid values in source variable 3\"\n",
    "    assert np.min(target) > 0, \"Invalid values in target\"\n",
    "    \n",
    "    count = len(source_var1)\n",
    "\n",
    "    # compute probabilities from (multi-dim) histogram frequencies\n",
    "    result, _ = np.histogramdd(\n",
    "        np.vstack([source_var1, source_var2, source_var3, target]).T, \n",
    "        bins=[np.max(source_var1), np.max(source_var2), np.max(source_var3), np.max(target)]\n",
    "    )\n",
    "    \n",
    "    return result / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_FIT_TE_DFI(feature, X, Y, hY, xtrap=20):\n",
    "    # Build the two four-variables probability distributions needed to compute FIT\n",
    "    pXYhYS = get_joint_prob_distr(feature, X, Y, hY)    # probability distribution for the PID with (Xp, Yp, Yt) as sources and S as target\n",
    "    pXShYY = get_joint_prob_distr(Y, X, feature, hY)    # probability distribution for the PID with (Xp, Yp, S) as sources and Yt as target\n",
    "\n",
    "    # Compute the two FIT atoms and FIT\n",
    "    sui_S = get_SUI(pXYhYS)\n",
    "    sui_Y = get_SUI(pXShYY)\n",
    "\n",
    "    fit = np.min([sui_S, sui_Y])\n",
    "\n",
    "    # Compute TE\n",
    "    te = compute_TE(pXYhYS)\n",
    "\n",
    "    # Compute DFI\n",
    "    dfi = compute_DFI(pXYhYS)\n",
    "\n",
    "    # Compute quadratic extrapolation bias correction for FIT and TE\n",
    "    fit_all = fit\n",
    "    te_all = te\n",
    "\n",
    "    FIT2 = np.zeros(xtrap)\n",
    "    FIT4 = np.zeros(xtrap)\n",
    "    TE2 = np.zeros(xtrap)\n",
    "    TE4 = np.zeros(xtrap)\n",
    "\n",
    "    for xIdx in range(xtrap):\n",
    "\n",
    "        numberOfTrials = len(X)\n",
    "\n",
    "        # Shuffled indexes in 0,ntrials range\n",
    "        rIdx = npr.choice(numberOfTrials, numberOfTrials, replace=False)\n",
    "        \n",
    "        # Divide the indexes in 2 and 4 parts\n",
    "        idx2 = np.array_split(rIdx, 2) \n",
    "        idx4 = np.array_split(rIdx, 4)\n",
    "        \n",
    "        # Stack all the sources in data, separate into 2 and 4 parts, and distinguish between s and y targets\n",
    "        data = np.stack(np.array([feature, X, Y, hY]),axis=1)\n",
    "        data2_s = np.stack(np.array([data[idx2[i]] for i in range(2)]), axis = 0)\n",
    "        data2_y = data2_s[:, :, [2, 1, 0, 3]]\n",
    "        data2_tot = np.stack(np.array([data2_s,data2_y]), axis=0)\n",
    "        \n",
    "        data4_s = np.stack(np.array([data[idx4[i]] for i in range(4)]), axis = 0)\n",
    "        data4_y = data4_s[:, :, [2, 1, 0, 3]]\n",
    "        data4_tot = np.stack(np.array([data4_s,data4_y]), axis=0)\n",
    "\n",
    "        # Compute Joint, SUI, FIT and TE for the 2 divided version\n",
    "        joint2 = [[\n",
    "            get_joint_prob_distr(*[data2_tot[ch,row, :, i] for i in range(4)])\n",
    "            for row in range(data2_tot.shape[1])]\n",
    "            for ch in range(data2_tot.shape[0])\n",
    "        ]\n",
    "        \n",
    "        SUI_2 = [[get_SUI(joint2[ch][i]) for i in range(2)] for ch in range(len(joint2))]\n",
    "\n",
    "        FIT2[xIdx] = np.mean(np.min(SUI_2, axis=0))\n",
    "        TE2[xIdx] = np.mean([compute_TE(joint2[0][i]) for i in range(2)])\n",
    "        \n",
    "        # Compute Joint, SUI, FIT and TE for the 4 divided version\n",
    "        joint4 = [[\n",
    "            get_joint_prob_distr(*[data4_tot[ch,row, :, i] for i in range(4)])\n",
    "            for row in range(data4_tot.shape[1])]\n",
    "            for ch in range(data4_tot.shape[0])\n",
    "        ]\n",
    "        \n",
    "        SUI_4 = [[get_SUI(joint4[ch][i]) for i in range(4)] for ch in range(len(joint4))]\n",
    "\n",
    "        FIT4[xIdx] = np.mean(np.min(SUI_4,axis=0))\n",
    "        TE4[xIdx] = np.mean([compute_TE(joint4[0][i]) for i in range(4)])\n",
    "\n",
    "    # Compute the linear and quadratic interpolations for FIT and TE\n",
    "\n",
    "    x = [1/len(idx2[0]), 1/len(idx4[0]), 1/len(rIdx)]\n",
    "    y = [np.mean(FIT4), np.mean(FIT2), fit_all]\n",
    "\n",
    "    p2 = np.polyfit(x, y, 2)\n",
    "    p1 = np.polyfit(x, y, 1) \n",
    "    FITQe = p2[2]\n",
    "    FITLe = p1[1]\n",
    "\n",
    "    y = [np.mean(TE4), np.mean(TE2), te_all]\n",
    "    \n",
    "    #print('prima del polyfit')\n",
    "\n",
    "    p2 = np.polyfit(x, y, 2)\n",
    "    p1 = np.polyfit(x, y, 1) \n",
    "    TEQe = p2[2]\n",
    "    TELe = p1[1]\n",
    "\n",
    "    #print('dopo del polyfit')\n",
    "         \n",
    "\n",
    "    return te, dfi, fit#, TEQe, TELe, FITQe, FITLe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not sim2A_ready:   \n",
    "    for simIdx in range(simReps):\n",
    "        print('Simulation number: ', simIdx, '\\n')\n",
    "    \n",
    "        for sigIdx in range(len(w_sig)):\n",
    "            for noiseIdx in range(len(w_noise)):\n",
    "                # draw the stimulus value for each trial\n",
    "                S = npr.randint(1, n_binsS + 1, size=nTrials)\n",
    "    \n",
    "                # simulate neural activity\n",
    "                X_noise = npr.normal(0, stdX_noise, size=(simLen, nTrials)) # Noise time series\n",
    "    \n",
    "                X_signal = eps * npr.normal(0, stdX_noise, size=(simLen, nTrials)) # Infinitesimal signal to avoid binning \n",
    "    \n",
    "                X_signal[stimWin[0]:stimWin[1],:] = np.tile(S, (stimWin[1]-stimWin[0], 1)) # Assigning Stimulus to Window\n",
    "    \n",
    "                # Adding multiplicative noise (we changed the dimension from nTrials to (simLen, nTrials) to have a different error for each time step)\n",
    "                X_signal = X_signal * (1 + npr.normal(0, stdX_sig, size=(simLen, nTrials))) \n",
    "    \n",
    "                # Time lagged single-trial input from the 2 dimensions of X and Y (we multpily everything by the weights, they mutiply only the stim/noise)\n",
    "                X2Ysig = w_sig[sigIdx] * np.vstack((eps * npr.normal(0, stdX_noise, size=(reps_delays[simIdx], nTrials)),\\\n",
    "                          X_signal[0:len(X_signal)-reps_delays[simIdx],:]))\n",
    "                X2Ynoise = w_noise[noiseIdx] * np.vstack((eps * npr.normal(0, stdX_noise, size=(reps_delays[simIdx], nTrials)),\\\n",
    "                          X_noise[0:len(X_signal)-reps_delays[simIdx],:]))\n",
    "    \n",
    "                # Computing Y + gaussian noise\n",
    "                Y = X2Ysig + X2Ynoise + npr.normal(0,stdY,size=(simLen, nTrials))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # START MODIFICA\n",
    "                # Saving Simulations for 2B\n",
    "                if (sigIdx == 10) and (noiseIdx == 5):\n",
    "                    S_B [simIdx] = S\n",
    "                    X_noise_B [simIdx]= X_noise\n",
    "                    X_signal_B [simIdx]= X_signal\n",
    "                    Y_B [simIdx]= Y\n",
    "    # END MODIFICA\n",
    "    \n",
    "    \n",
    "    \n",
    "                # First time point at which Y receives stim info from X\n",
    "                t = stimWin[0] + reps_delays[simIdx]\n",
    "                d = reps_delays[simIdx]\n",
    "    \n",
    "                # Discretize Neural Activity\n",
    "                _, bin_edges = pd.cut(X_noise[t-d,:], n_binsX, retbins=True)\n",
    "                bX_noise = np.digitize(X_noise[t-d, :], bins=bin_edges, right=True)\n",
    "    \n",
    "                _, bin_edges = pd.cut(X_signal[t-d,:], n_binsX, retbins=True)\n",
    "                bX_sig = np.digitize(X_signal[t-d,:], bins=bin_edges, right=True)\n",
    "    \n",
    "                #_, bin_edges = pd.cut(X[t-d,:], n_binsX, retbins=True)\n",
    "                #bX = np.digitize(X[t-d,:], bins=bin_edges, right=True)\n",
    "    \n",
    "                _, bin_edges = pd.cut(Y[t,:], n_binsY, retbins=True)\n",
    "                bYt = np.digitize(Y[t,:], bins=bin_edges, right=True)\n",
    "    \n",
    "                _, bin_edges = pd.cut(Y[t-d,:], n_binsY, retbins=True)\n",
    "                bYpast = np.digitize(Y[t-d,:], bins=bin_edges, right=True)\n",
    "    \n",
    "                bX = (bX_sig - 1) * n_binsX + bX_noise\n",
    "    \n",
    "                te_A[simIdx][sigIdx][noiseIdx], dfi_A[simIdx][sigIdx][noiseIdx], fit_A[simIdx][sigIdx][noiseIdx] = compute_FIT_TE_DFI(S, bX, bYt, bYpast)\n",
    "    \n",
    "    np.savez(file_2A, te_A=te_A, dfi_A=dfi_A, fit_A=fit_A)\n",
    "\n",
    "else:\n",
    "    npzfile_2A = np.load(file_2A)\n",
    "\n",
    "    te_A = npzfile_2A['te_A']\n",
    "    dfi_A = npzfile_2A['dfi_A']\n",
    "    fit_A = npzfile_2A['fit_A']\n",
    "\n",
    "###### CONTINUAAAAA\n",
    "                ######## SHUFFLING ########\n",
    "    \n",
    "                #   XSh = np.empty_like(bX)\n",
    "    \n",
    "                #   for shIdx in range(nShuff):\n",
    "                #       for Ss in np.unique(S):\n",
    "                #           idx = (S == Ss)\n",
    "                #           tmpX = bX[idx]\n",
    "                #           rIdx = npr.choice(np.sum(idx), np.sum(idx), replace=False)\n",
    "                #           XSh[idx] = tmpX[rIdx]\n",
    "                #   \n",
    "                #   dish_cond, dfish_cond, fitsh_cond = compute_FIT_TE(S, XSh, bYt, bYpast)\n",
    "    \n",
    "                #   idx = npr.choice(nTrials, nTrials, replace=False)\n",
    "                #   Ssh = S[idx]\n",
    "                #   XSh = bX[idx]\n",
    "    \n",
    "                #   _, dfish, fitsh = compute_FIT_TE(Ssh, bX, bYt, bYpast)\n",
    "                #   dish = DI_infToolBox(XSh, bYt, bYpast, 'naive', 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "# Display the matrix using imshow.\n",
    "# 'extent' sets the axes limits and 'origin' ensures y=0 is at the bottom.\n",
    "white_blue = LinearSegmentedColormap.from_list(\"white_blue\", [\"white\", \"blue\"])\n",
    "plt.imshow(np.mean(fit,axis=0), extent=[0, 1, 0, 1], origin='lower', cmap=white_blue)\n",
    "plt.colorbar(label='Bits')\n",
    "plt.xlabel('$W_{noise}$')\n",
    "plt.ylabel('$W_{stim}$')\n",
    "plt.title('FIT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "# Display the matrix using imshow.\n",
    "# 'extent' sets the axes limits and 'origin' ensures y=0 is at the bottom.\n",
    "white_blue = LinearSegmentedColormap.from_list(\"white_blue\", [\"white\", \"blue\"])\n",
    "plt.imshow(np.mean(te,axis=0), extent=[0, 1, 0, 1], origin='lower', cmap=white_blue)\n",
    "plt.colorbar(label='Bits')\n",
    "plt.xlabel('$W_{noise}$')\n",
    "plt.ylabel('$W_{stim}$')\n",
    "plt.title('TE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run If you didn't run 2A\n",
    "\n",
    "\n",
    "for simIdx in range(simReps):\n",
    "    S = npr.randint(1, n_binsS + 1, size=nTrials)\n",
    "\n",
    "    # simulate neural activity\n",
    "    X_noise = npr.normal(0, stdX_noise, size=(simLen, nTrials)) # Noise time series\n",
    "\n",
    "    X_signal = eps * npr.normal(0, stdX_noise, size=(simLen, nTrials)) # Infinitesimal signal to avoid binning \n",
    "\n",
    "    X_signal[stimWin[0]:stimWin[1],:] = np.tile(S, (stimWin[1]-stimWin[0], 1)) # Assigning Stimulus to Window\n",
    "\n",
    "    # Adding multiplicative noise (we changed the dimension from nTrials to (simLen, nTrials) to have a different error for each time step)\n",
    "    X_signal = X_signal * (1 + npr.normal(0, stdX_sig, size=(simLen, nTrials))) \n",
    "\n",
    "    # Time lagged single-trial input from the 2 dimensions of X and Y (we multpily everything by the weights, they mutiply only the stim/noise)\n",
    "    X2Ysig = w_sig[10] * np.vstack((eps * npr.normal(0, stdX_noise, size=(reps_delays[simIdx], nTrials)),\\\n",
    "                      X_signal[0:len(X_signal)-reps_delays[simIdx],:]))\n",
    "    X2Ynoise = w_noise[5] * np.vstack((eps * npr.normal(0, stdX_noise, size=(reps_delays[simIdx], nTrials)),\\\n",
    "                      X_noise[0:len(X_signal)-reps_delays[simIdx],:]))\n",
    "\n",
    "    # Computing Y + gaussian noise\n",
    "    Y = X2Ysig + X2Ynoise + npr.normal(0,stdY,size=(simLen, nTrials))\n",
    "\n",
    "    S_mat = np.tile(S, (60, 1))\n",
    "    S_B [simIdx] = S_mat\n",
    "    X_noise_B [simIdx]= X_noise\n",
    "    X_signal_B [simIdx]= X_signal\n",
    "    Y_B [simIdx]= Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation number:  0 \n",
      "\n",
      "t:  0 d:  0\n",
      "t:  0 d:  1\n",
      "t:  0 d:  2\n",
      "t:  0 d:  3\n",
      "t:  0 d:  4\n",
      "t:  0 d:  5\n",
      "t:  0 d:  6\n",
      "t:  0 d:  7\n",
      "t:  0 d:  8\n",
      "t:  0 d:  9\n",
      "t:  1 d:  0\n",
      "t:  1 d:  1\n",
      "t:  1 d:  2\n",
      "t:  1 d:  3\n",
      "t:  1 d:  4\n",
      "t:  1 d:  5\n",
      "t:  1 d:  6\n",
      "t:  1 d:  7\n",
      "t:  1 d:  8\n",
      "t:  1 d:  9\n",
      "t:  2 d:  0\n",
      "t:  2 d:  1\n",
      "t:  2 d:  2\n",
      "t:  2 d:  3\n",
      "t:  2 d:  4\n",
      "t:  2 d:  5\n",
      "t:  2 d:  6\n",
      "t:  2 d:  7\n",
      "t:  2 d:  8\n",
      "t:  2 d:  9\n",
      "t:  3 d:  0\n",
      "t:  3 d:  1\n",
      "t:  3 d:  2\n",
      "t:  3 d:  3\n",
      "t:  3 d:  4\n",
      "t:  3 d:  5\n",
      "t:  3 d:  6\n",
      "t:  3 d:  7\n",
      "t:  3 d:  8\n",
      "t:  3 d:  9\n",
      "t:  4 d:  0\n",
      "t:  4 d:  1\n",
      "t:  4 d:  2\n",
      "t:  4 d:  3\n",
      "t:  4 d:  4\n",
      "t:  4 d:  5\n",
      "t:  4 d:  6\n",
      "t:  4 d:  7\n",
      "t:  4 d:  8\n",
      "t:  4 d:  9\n",
      "t:  5 d:  0\n",
      "t:  5 d:  1\n",
      "t:  5 d:  2\n",
      "t:  5 d:  3\n",
      "t:  5 d:  4\n",
      "t:  5 d:  5\n",
      "t:  5 d:  6\n",
      "t:  5 d:  7\n",
      "t:  5 d:  8\n",
      "t:  5 d:  9\n",
      "t:  6 d:  0\n",
      "t:  6 d:  1\n",
      "t:  6 d:  2\n",
      "t:  6 d:  3\n",
      "t:  6 d:  4\n",
      "t:  6 d:  5\n",
      "t:  6 d:  6\n",
      "t:  6 d:  7\n",
      "t:  6 d:  8\n",
      "t:  6 d:  9\n",
      "t:  7 d:  0\n",
      "t:  7 d:  1\n",
      "t:  7 d:  2\n",
      "t:  7 d:  3\n",
      "t:  7 d:  4\n",
      "t:  7 d:  5\n",
      "t:  7 d:  6\n",
      "t:  7 d:  7\n",
      "t:  7 d:  8\n",
      "t:  7 d:  9\n",
      "t:  8 d:  0\n",
      "t:  8 d:  1\n",
      "t:  8 d:  2\n",
      "t:  8 d:  3\n",
      "t:  8 d:  4\n",
      "t:  8 d:  5\n",
      "t:  8 d:  6\n",
      "t:  8 d:  7\n",
      "t:  8 d:  8\n",
      "t:  8 d:  9\n",
      "t:  9 d:  0\n",
      "t:  9 d:  1\n",
      "t:  9 d:  2\n",
      "t:  9 d:  3\n",
      "t:  9 d:  4\n",
      "t:  9 d:  5\n",
      "t:  9 d:  6\n",
      "t:  9 d:  7\n",
      "t:  9 d:  8\n",
      "t:  9 d:  9\n",
      "t:  10 d:  0\n",
      "t:  10 d:  1\n",
      "t:  10 d:  2\n",
      "t:  10 d:  3\n",
      "t:  10 d:  4\n",
      "t:  10 d:  5\n",
      "t:  10 d:  6\n",
      "t:  10 d:  7\n",
      "t:  10 d:  8\n",
      "t:  10 d:  9\n",
      "t:  11 d:  0\n",
      "t:  11 d:  1\n",
      "t:  11 d:  2\n",
      "t:  11 d:  3\n",
      "t:  11 d:  4\n",
      "t:  11 d:  5\n",
      "t:  11 d:  6\n",
      "t:  11 d:  7\n",
      "t:  11 d:  8\n",
      "t:  11 d:  9\n",
      "t:  12 d:  0\n",
      "t:  12 d:  1\n",
      "t:  12 d:  2\n",
      "t:  12 d:  3\n",
      "t:  12 d:  4\n",
      "t:  12 d:  5\n",
      "t:  12 d:  6\n",
      "t:  12 d:  7\n",
      "t:  12 d:  8\n",
      "t:  12 d:  9\n",
      "t:  13 d:  0\n",
      "t:  13 d:  1\n",
      "t:  13 d:  2\n",
      "t:  13 d:  3\n",
      "t:  13 d:  4\n",
      "t:  13 d:  5\n",
      "t:  13 d:  6\n",
      "t:  13 d:  7\n",
      "t:  13 d:  8\n",
      "t:  13 d:  9\n",
      "t:  14 d:  0\n",
      "t:  14 d:  1\n",
      "t:  14 d:  2\n",
      "t:  14 d:  3\n",
      "t:  14 d:  4\n",
      "t:  14 d:  5\n",
      "t:  14 d:  6\n",
      "t:  14 d:  7\n",
      "t:  14 d:  8\n",
      "t:  14 d:  9\n",
      "t:  15 d:  0\n",
      "t:  15 d:  1\n",
      "t:  15 d:  2\n",
      "t:  15 d:  3\n",
      "t:  15 d:  4\n",
      "t:  15 d:  5\n",
      "t:  15 d:  6\n",
      "t:  15 d:  7\n",
      "t:  15 d:  8\n",
      "t:  15 d:  9\n",
      "t:  16 d:  0\n",
      "t:  16 d:  1\n",
      "t:  16 d:  2\n",
      "t:  16 d:  3\n",
      "t:  16 d:  4\n",
      "t:  16 d:  5\n",
      "t:  16 d:  6\n",
      "t:  16 d:  7\n",
      "t:  16 d:  8\n",
      "t:  16 d:  9\n",
      "t:  17 d:  0\n",
      "t:  17 d:  1\n",
      "t:  17 d:  2\n",
      "t:  17 d:  3\n",
      "t:  17 d:  4\n",
      "t:  17 d:  5\n",
      "t:  17 d:  6\n",
      "t:  17 d:  7\n",
      "t:  17 d:  8\n",
      "t:  17 d:  9\n",
      "t:  18 d:  0\n",
      "t:  18 d:  1\n",
      "t:  18 d:  2\n",
      "t:  18 d:  3\n",
      "t:  18 d:  4\n",
      "t:  18 d:  5\n",
      "t:  18 d:  6\n",
      "t:  18 d:  7\n",
      "t:  18 d:  8\n",
      "t:  18 d:  9\n",
      "t:  19 d:  0\n",
      "t:  19 d:  1\n",
      "t:  19 d:  2\n",
      "t:  19 d:  3\n",
      "t:  19 d:  4\n",
      "t:  19 d:  5\n",
      "t:  19 d:  6\n",
      "t:  19 d:  7\n",
      "t:  19 d:  8\n",
      "t:  19 d:  9\n",
      "t:  20 d:  0\n",
      "t:  20 d:  1\n",
      "t:  20 d:  2\n",
      "t:  20 d:  3\n",
      "t:  20 d:  4\n",
      "t:  20 d:  5\n",
      "t:  20 d:  6\n",
      "t:  20 d:  7\n",
      "t:  20 d:  8\n",
      "t:  20 d:  9\n",
      "t:  21 d:  0\n",
      "t:  21 d:  1\n",
      "t:  21 d:  2\n",
      "t:  21 d:  3\n",
      "t:  21 d:  4\n",
      "t:  21 d:  5\n",
      "t:  21 d:  6\n",
      "t:  21 d:  7\n",
      "t:  21 d:  8\n",
      "t:  21 d:  9\n",
      "t:  22 d:  0\n",
      "t:  22 d:  1\n",
      "t:  22 d:  2\n",
      "t:  22 d:  3\n",
      "t:  22 d:  4\n",
      "t:  22 d:  5\n",
      "t:  22 d:  6\n",
      "t:  22 d:  7\n",
      "t:  22 d:  8\n",
      "t:  22 d:  9\n",
      "t:  23 d:  0\n",
      "t:  23 d:  1\n",
      "t:  23 d:  2\n",
      "t:  23 d:  3\n",
      "t:  23 d:  4\n",
      "t:  23 d:  5\n",
      "t:  23 d:  6\n",
      "t:  23 d:  7\n",
      "t:  23 d:  8\n",
      "t:  23 d:  9\n",
      "t:  24 d:  0\n",
      "t:  24 d:  1\n",
      "t:  24 d:  2\n",
      "t:  24 d:  3\n",
      "t:  24 d:  4\n",
      "t:  24 d:  5\n",
      "t:  24 d:  6\n",
      "t:  24 d:  7\n",
      "t:  24 d:  8\n",
      "t:  24 d:  9\n",
      "t:  25 d:  0\n",
      "t:  25 d:  1\n",
      "t:  25 d:  2\n",
      "t:  25 d:  3\n",
      "t:  25 d:  4\n",
      "t:  25 d:  5\n",
      "t:  25 d:  6\n",
      "t:  25 d:  7\n",
      "t:  25 d:  8\n",
      "t:  25 d:  9\n",
      "t:  26 d:  0\n",
      "t:  26 d:  1\n",
      "t:  26 d:  2\n",
      "t:  26 d:  3\n",
      "t:  26 d:  4\n",
      "t:  26 d:  5\n",
      "t:  26 d:  6\n",
      "t:  26 d:  7\n",
      "t:  26 d:  8\n",
      "t:  26 d:  9\n",
      "t:  27 d:  0\n",
      "t:  27 d:  1\n",
      "t:  27 d:  2\n",
      "t:  27 d:  3\n",
      "t:  27 d:  4\n",
      "t:  27 d:  5\n",
      "t:  27 d:  6\n",
      "t:  27 d:  7\n",
      "t:  27 d:  8\n",
      "t:  27 d:  9\n",
      "t:  28 d:  0\n",
      "t:  28 d:  1\n",
      "t:  28 d:  2\n",
      "t:  28 d:  3\n",
      "t:  28 d:  4\n",
      "t:  28 d:  5\n",
      "t:  28 d:  6\n",
      "t:  28 d:  7\n",
      "t:  28 d:  8\n",
      "t:  28 d:  9\n",
      "t:  29 d:  0\n",
      "t:  29 d:  1\n",
      "t:  29 d:  2\n",
      "t:  29 d:  3\n",
      "t:  29 d:  4\n",
      "t:  29 d:  5\n",
      "t:  29 d:  6\n",
      "t:  29 d:  7\n",
      "t:  29 d:  8\n",
      "t:  29 d:  9\n",
      "t:  30 d:  0\n",
      "t:  30 d:  1\n",
      "t:  30 d:  2\n",
      "t:  30 d:  3\n",
      "t:  30 d:  4\n",
      "t:  30 d:  5\n",
      "t:  30 d:  6\n",
      "t:  30 d:  7\n",
      "t:  30 d:  8\n",
      "t:  30 d:  9\n",
      "t:  31 d:  0\n",
      "t:  31 d:  1\n",
      "t:  31 d:  2\n",
      "t:  31 d:  3\n",
      "t:  31 d:  4\n",
      "t:  31 d:  5\n",
      "t:  31 d:  6\n",
      "t:  31 d:  7\n",
      "t:  31 d:  8\n",
      "t:  31 d:  9\n",
      "t:  32 d:  0\n",
      "t:  32 d:  1\n",
      "t:  32 d:  2\n",
      "t:  32 d:  3\n",
      "t:  32 d:  4\n",
      "t:  32 d:  5\n",
      "t:  32 d:  6\n",
      "t:  32 d:  7\n",
      "t:  32 d:  8\n",
      "t:  32 d:  9\n",
      "t:  33 d:  0\n",
      "t:  33 d:  1\n",
      "t:  33 d:  2\n",
      "t:  33 d:  3\n",
      "t:  33 d:  4\n",
      "t:  33 d:  5\n",
      "t:  33 d:  6\n",
      "t:  33 d:  7\n",
      "t:  33 d:  8\n",
      "t:  33 d:  9\n",
      "t:  34 d:  0\n",
      "t:  34 d:  1\n",
      "t:  34 d:  2\n",
      "t:  34 d:  3\n",
      "t:  34 d:  4\n",
      "t:  34 d:  5\n",
      "t:  34 d:  6\n",
      "t:  34 d:  7\n",
      "t:  34 d:  8\n",
      "t:  34 d:  9\n",
      "t:  35 d:  0\n",
      "t:  35 d:  1\n",
      "t:  35 d:  2\n",
      "t:  35 d:  3\n",
      "t:  35 d:  4\n",
      "t:  35 d:  5\n",
      "t:  35 d:  6\n",
      "t:  35 d:  7\n",
      "t:  35 d:  8\n",
      "t:  35 d:  9\n",
      "t:  36 d:  0\n",
      "t:  36 d:  1\n",
      "t:  36 d:  2\n",
      "t:  36 d:  3\n",
      "t:  36 d:  4\n",
      "t:  36 d:  5\n",
      "t:  36 d:  6\n",
      "t:  36 d:  7\n",
      "t:  36 d:  8\n",
      "t:  36 d:  9\n",
      "t:  37 d:  0\n",
      "t:  37 d:  1\n",
      "t:  37 d:  2\n",
      "t:  37 d:  3\n",
      "t:  37 d:  4\n",
      "t:  37 d:  5\n",
      "t:  37 d:  6\n",
      "t:  37 d:  7\n",
      "t:  37 d:  8\n",
      "t:  37 d:  9\n",
      "t:  38 d:  0\n",
      "t:  38 d:  1\n",
      "t:  38 d:  2\n",
      "t:  38 d:  3\n",
      "t:  38 d:  4\n",
      "t:  38 d:  5\n",
      "t:  38 d:  6\n",
      "t:  38 d:  7\n",
      "t:  38 d:  8\n",
      "t:  38 d:  9\n",
      "t:  39 d:  0\n",
      "t:  39 d:  1\n",
      "t:  39 d:  2\n",
      "t:  39 d:  3\n",
      "t:  39 d:  4\n",
      "t:  39 d:  5\n",
      "t:  39 d:  6\n",
      "t:  39 d:  7\n",
      "t:  39 d:  8\n",
      "t:  39 d:  9\n",
      "t:  40 d:  0\n",
      "t:  40 d:  1\n",
      "t:  40 d:  2\n",
      "t:  40 d:  3\n",
      "t:  40 d:  4\n",
      "t:  40 d:  5\n",
      "t:  40 d:  6\n",
      "t:  40 d:  7\n",
      "t:  40 d:  8\n",
      "t:  40 d:  9\n",
      "t:  41 d:  0\n",
      "t:  41 d:  1\n",
      "t:  41 d:  2\n",
      "t:  41 d:  3\n",
      "t:  41 d:  4\n",
      "t:  41 d:  5\n",
      "t:  41 d:  6\n",
      "t:  41 d:  7\n",
      "t:  41 d:  8\n",
      "t:  41 d:  9\n",
      "t:  42 d:  0\n",
      "t:  42 d:  1\n",
      "t:  42 d:  2\n",
      "t:  42 d:  3\n",
      "t:  42 d:  4\n",
      "t:  42 d:  5\n",
      "t:  42 d:  6\n",
      "t:  42 d:  7\n",
      "t:  42 d:  8\n",
      "t:  42 d:  9\n",
      "t:  43 d:  0\n",
      "t:  43 d:  1\n",
      "t:  43 d:  2\n",
      "t:  43 d:  3\n",
      "t:  43 d:  4\n",
      "t:  43 d:  5\n",
      "t:  43 d:  6\n",
      "t:  43 d:  7\n",
      "t:  43 d:  8\n",
      "t:  43 d:  9\n",
      "t:  44 d:  0\n",
      "t:  44 d:  1\n",
      "t:  44 d:  2\n",
      "t:  44 d:  3\n",
      "t:  44 d:  4\n",
      "t:  44 d:  5\n",
      "t:  44 d:  6\n",
      "t:  44 d:  7\n",
      "t:  44 d:  8\n",
      "t:  44 d:  9\n",
      "t:  45 d:  0\n",
      "t:  45 d:  1\n",
      "t:  45 d:  2\n",
      "t:  45 d:  3\n",
      "t:  45 d:  4\n",
      "t:  45 d:  5\n",
      "t:  45 d:  6\n",
      "t:  45 d:  7\n",
      "t:  45 d:  8\n",
      "t:  45 d:  9\n",
      "t:  46 d:  0\n",
      "t:  46 d:  1\n",
      "t:  46 d:  2\n",
      "t:  46 d:  3\n",
      "t:  46 d:  4\n",
      "t:  46 d:  5\n",
      "t:  46 d:  6\n",
      "t:  46 d:  7\n",
      "t:  46 d:  8\n",
      "t:  46 d:  9\n",
      "t:  47 d:  0\n",
      "t:  47 d:  1\n",
      "t:  47 d:  2\n",
      "t:  47 d:  3\n",
      "t:  47 d:  4\n",
      "t:  47 d:  5\n",
      "t:  47 d:  6\n",
      "t:  47 d:  7\n",
      "t:  47 d:  8\n",
      "t:  47 d:  9\n",
      "t:  48 d:  0\n",
      "t:  48 d:  1\n",
      "t:  48 d:  2\n",
      "t:  48 d:  3\n",
      "t:  48 d:  4\n",
      "t:  48 d:  5\n",
      "t:  48 d:  6\n",
      "t:  48 d:  7\n",
      "t:  48 d:  8\n",
      "t:  48 d:  9\n",
      "t:  49 d:  0\n",
      "t:  49 d:  1\n",
      "t:  49 d:  2\n",
      "t:  49 d:  3\n",
      "t:  49 d:  4\n",
      "t:  49 d:  5\n",
      "t:  49 d:  6\n",
      "t:  49 d:  7\n",
      "t:  49 d:  8\n",
      "t:  49 d:  9\n",
      "t:  50 d:  0\n",
      "t:  50 d:  1\n",
      "t:  50 d:  2\n",
      "t:  50 d:  3\n",
      "t:  50 d:  4\n",
      "t:  50 d:  5\n",
      "t:  50 d:  6\n",
      "t:  50 d:  7\n",
      "t:  50 d:  8\n",
      "t:  50 d:  9\n",
      "t:  51 d:  0\n",
      "t:  51 d:  1\n",
      "t:  51 d:  2\n",
      "t:  51 d:  3\n",
      "t:  51 d:  4\n",
      "t:  51 d:  5\n",
      "t:  51 d:  6\n",
      "t:  51 d:  7\n",
      "t:  51 d:  8\n",
      "t:  51 d:  9\n",
      "t:  52 d:  0\n",
      "t:  52 d:  1\n",
      "t:  52 d:  2\n",
      "t:  52 d:  3\n",
      "t:  52 d:  4\n",
      "t:  52 d:  5\n",
      "t:  52 d:  6\n",
      "t:  52 d:  7\n",
      "t:  52 d:  8\n",
      "t:  52 d:  9\n",
      "t:  53 d:  0\n",
      "t:  53 d:  1\n",
      "t:  53 d:  2\n",
      "t:  53 d:  3\n",
      "t:  53 d:  4\n",
      "t:  53 d:  5\n",
      "t:  53 d:  6\n",
      "t:  53 d:  7\n",
      "t:  53 d:  8\n",
      "t:  53 d:  9\n",
      "t:  54 d:  0\n",
      "t:  54 d:  1\n",
      "t:  54 d:  2\n",
      "t:  54 d:  3\n",
      "t:  54 d:  4\n",
      "t:  54 d:  5\n",
      "t:  54 d:  6\n",
      "t:  54 d:  7\n",
      "t:  54 d:  8\n",
      "t:  54 d:  9\n",
      "t:  55 d:  0\n",
      "t:  55 d:  1\n",
      "t:  55 d:  2\n",
      "t:  55 d:  3\n",
      "t:  55 d:  4\n",
      "t:  55 d:  5\n",
      "t:  55 d:  6\n",
      "t:  55 d:  7\n",
      "t:  55 d:  8\n",
      "t:  55 d:  9\n",
      "t:  56 d:  0\n",
      "t:  56 d:  1\n",
      "t:  56 d:  2\n",
      "t:  56 d:  3\n",
      "t:  56 d:  4\n",
      "t:  56 d:  5\n",
      "t:  56 d:  6\n",
      "t:  56 d:  7\n",
      "t:  56 d:  8\n",
      "t:  56 d:  9\n",
      "t:  57 d:  0\n",
      "t:  57 d:  1\n",
      "t:  57 d:  2\n",
      "t:  57 d:  3\n",
      "t:  57 d:  4\n",
      "t:  57 d:  5\n",
      "t:  57 d:  6\n",
      "t:  57 d:  7\n",
      "t:  57 d:  8\n",
      "t:  57 d:  9\n",
      "t:  58 d:  0\n",
      "t:  58 d:  1\n",
      "t:  58 d:  2\n",
      "t:  58 d:  3\n",
      "t:  58 d:  4\n",
      "t:  58 d:  5\n",
      "t:  58 d:  6\n",
      "t:  58 d:  7\n",
      "t:  58 d:  8\n",
      "t:  58 d:  9\n",
      "t:  59 d:  0\n",
      "t:  59 d:  1\n",
      "t:  59 d:  2\n",
      "t:  59 d:  3\n",
      "t:  59 d:  4\n",
      "t:  59 d:  5\n",
      "t:  59 d:  6\n",
      "t:  59 d:  7\n",
      "t:  59 d:  8\n",
      "t:  59 d:  9\n",
      "Simulation number:  1 \n",
      "\n",
      "t:  0 d:  0\n",
      "t:  0 d:  1\n",
      "t:  0 d:  2\n",
      "t:  0 d:  3\n",
      "t:  0 d:  4\n",
      "t:  0 d:  5\n",
      "t:  0 d:  6\n",
      "t:  0 d:  7\n",
      "t:  0 d:  8\n",
      "t:  0 d:  9\n",
      "t:  1 d:  0\n",
      "t:  1 d:  1\n",
      "t:  1 d:  2\n",
      "t:  1 d:  3\n",
      "t:  1 d:  4\n",
      "t:  1 d:  5\n",
      "t:  1 d:  6\n",
      "t:  1 d:  7\n",
      "t:  1 d:  8\n",
      "t:  1 d:  9\n",
      "t:  2 d:  0\n",
      "t:  2 d:  1\n",
      "t:  2 d:  2\n",
      "t:  2 d:  3\n",
      "t:  2 d:  4\n",
      "t:  2 d:  5\n",
      "t:  2 d:  6\n",
      "t:  2 d:  7\n",
      "t:  2 d:  8\n",
      "t:  2 d:  9\n",
      "t:  3 d:  0\n",
      "t:  3 d:  1\n",
      "t:  3 d:  2\n",
      "t:  3 d:  3\n",
      "t:  3 d:  4\n",
      "t:  3 d:  5\n",
      "t:  3 d:  6\n",
      "t:  3 d:  7\n",
      "t:  3 d:  8\n",
      "t:  3 d:  9\n",
      "t:  4 d:  0\n",
      "t:  4 d:  1\n",
      "t:  4 d:  2\n",
      "t:  4 d:  3\n",
      "t:  4 d:  4\n",
      "t:  4 d:  5\n",
      "t:  4 d:  6\n",
      "t:  4 d:  7\n",
      "t:  4 d:  8\n",
      "t:  4 d:  9\n",
      "t:  5 d:  0\n",
      "t:  5 d:  1\n",
      "t:  5 d:  2\n",
      "t:  5 d:  3\n",
      "t:  5 d:  4\n",
      "t:  5 d:  5\n",
      "t:  5 d:  6\n",
      "t:  5 d:  7\n",
      "t:  5 d:  8\n",
      "t:  5 d:  9\n",
      "t:  6 d:  0\n",
      "t:  6 d:  1\n",
      "t:  6 d:  2\n",
      "t:  6 d:  3\n",
      "t:  6 d:  4\n",
      "t:  6 d:  5\n",
      "t:  6 d:  6\n",
      "t:  6 d:  7\n",
      "t:  6 d:  8\n",
      "t:  6 d:  9\n",
      "t:  7 d:  0\n",
      "t:  7 d:  1\n",
      "t:  7 d:  2\n",
      "t:  7 d:  3\n",
      "t:  7 d:  4\n",
      "t:  7 d:  5\n",
      "t:  7 d:  6\n",
      "t:  7 d:  7\n",
      "t:  7 d:  8\n",
      "t:  7 d:  9\n",
      "t:  8 d:  0\n",
      "t:  8 d:  1\n",
      "t:  8 d:  2\n",
      "t:  8 d:  3\n",
      "t:  8 d:  4\n",
      "t:  8 d:  5\n",
      "t:  8 d:  6\n",
      "t:  8 d:  7\n",
      "t:  8 d:  8\n",
      "t:  8 d:  9\n",
      "t:  9 d:  0\n",
      "t:  9 d:  1\n",
      "t:  9 d:  2\n",
      "t:  9 d:  3\n",
      "t:  9 d:  4\n",
      "t:  9 d:  5\n",
      "t:  9 d:  6\n",
      "t:  9 d:  7\n",
      "t:  9 d:  8\n",
      "t:  9 d:  9\n",
      "t:  10 d:  0\n",
      "t:  10 d:  1\n",
      "t:  10 d:  2\n",
      "t:  10 d:  3\n",
      "t:  10 d:  4\n",
      "t:  10 d:  5\n",
      "t:  10 d:  6\n",
      "t:  10 d:  7\n",
      "t:  10 d:  8\n",
      "t:  10 d:  9\n",
      "t:  11 d:  0\n",
      "t:  11 d:  1\n",
      "t:  11 d:  2\n",
      "t:  11 d:  3\n",
      "t:  11 d:  4\n",
      "t:  11 d:  5\n",
      "t:  11 d:  6\n",
      "t:  11 d:  7\n",
      "t:  11 d:  8\n",
      "t:  11 d:  9\n",
      "t:  12 d:  0\n",
      "t:  12 d:  1\n",
      "t:  12 d:  2\n",
      "t:  12 d:  3\n",
      "t:  12 d:  4\n",
      "t:  12 d:  5\n",
      "t:  12 d:  6\n",
      "t:  12 d:  7\n",
      "t:  12 d:  8\n",
      "t:  12 d:  9\n",
      "t:  13 d:  0\n",
      "t:  13 d:  1\n",
      "t:  13 d:  2\n",
      "t:  13 d:  3\n",
      "t:  13 d:  4\n",
      "t:  13 d:  5\n",
      "t:  13 d:  6\n",
      "t:  13 d:  7\n",
      "t:  13 d:  8\n",
      "t:  13 d:  9\n",
      "t:  14 d:  0\n",
      "t:  14 d:  1\n",
      "t:  14 d:  2\n",
      "t:  14 d:  3\n",
      "t:  14 d:  4\n",
      "t:  14 d:  5\n",
      "t:  14 d:  6\n",
      "t:  14 d:  7\n",
      "t:  14 d:  8\n",
      "t:  14 d:  9\n",
      "t:  15 d:  0\n",
      "t:  15 d:  1\n",
      "t:  15 d:  2\n",
      "t:  15 d:  3\n",
      "t:  15 d:  4\n",
      "t:  15 d:  5\n",
      "t:  15 d:  6\n",
      "t:  15 d:  7\n",
      "t:  15 d:  8\n",
      "t:  15 d:  9\n",
      "t:  16 d:  0\n",
      "t:  16 d:  1\n",
      "t:  16 d:  2\n",
      "t:  16 d:  3\n",
      "t:  16 d:  4\n",
      "t:  16 d:  5\n",
      "t:  16 d:  6\n",
      "t:  16 d:  7\n",
      "t:  16 d:  8\n",
      "t:  16 d:  9\n",
      "t:  17 d:  0\n",
      "t:  17 d:  1\n",
      "t:  17 d:  2\n",
      "t:  17 d:  3\n",
      "t:  17 d:  4\n",
      "t:  17 d:  5\n",
      "t:  17 d:  6\n",
      "t:  17 d:  7\n",
      "t:  17 d:  8\n",
      "t:  17 d:  9\n",
      "t:  18 d:  0\n",
      "t:  18 d:  1\n",
      "t:  18 d:  2\n",
      "t:  18 d:  3\n",
      "t:  18 d:  4\n",
      "t:  18 d:  5\n",
      "t:  18 d:  6\n",
      "t:  18 d:  7\n",
      "t:  18 d:  8\n",
      "t:  18 d:  9\n",
      "t:  19 d:  0\n",
      "t:  19 d:  1\n",
      "t:  19 d:  2\n",
      "t:  19 d:  3\n",
      "t:  19 d:  4\n",
      "t:  19 d:  5\n",
      "t:  19 d:  6\n",
      "t:  19 d:  7\n",
      "t:  19 d:  8\n",
      "t:  19 d:  9\n",
      "t:  20 d:  0\n",
      "t:  20 d:  1\n",
      "t:  20 d:  2\n",
      "t:  20 d:  3\n",
      "t:  20 d:  4\n",
      "t:  20 d:  5\n",
      "t:  20 d:  6\n",
      "t:  20 d:  7\n",
      "t:  20 d:  8\n",
      "t:  20 d:  9\n",
      "t:  21 d:  0\n",
      "t:  21 d:  1\n",
      "t:  21 d:  2\n",
      "t:  21 d:  3\n",
      "t:  21 d:  4\n",
      "t:  21 d:  5\n",
      "t:  21 d:  6\n",
      "t:  21 d:  7\n",
      "t:  21 d:  8\n",
      "t:  21 d:  9\n",
      "t:  22 d:  0\n",
      "t:  22 d:  1\n",
      "t:  22 d:  2\n",
      "t:  22 d:  3\n",
      "t:  22 d:  4\n",
      "t:  22 d:  5\n",
      "t:  22 d:  6\n",
      "t:  22 d:  7\n",
      "t:  22 d:  8\n",
      "t:  22 d:  9\n",
      "t:  23 d:  0\n",
      "t:  23 d:  1\n",
      "t:  23 d:  2\n",
      "t:  23 d:  3\n",
      "t:  23 d:  4\n",
      "t:  23 d:  5\n",
      "t:  23 d:  6\n",
      "t:  23 d:  7\n",
      "t:  23 d:  8\n",
      "t:  23 d:  9\n",
      "t:  24 d:  0\n",
      "t:  24 d:  1\n",
      "t:  24 d:  2\n",
      "t:  24 d:  3\n",
      "t:  24 d:  4\n",
      "t:  24 d:  5\n",
      "t:  24 d:  6\n",
      "t:  24 d:  7\n",
      "t:  24 d:  8\n",
      "t:  24 d:  9\n",
      "t:  25 d:  0\n",
      "t:  25 d:  1\n",
      "t:  25 d:  2\n",
      "t:  25 d:  3\n",
      "t:  25 d:  4\n",
      "t:  25 d:  5\n",
      "t:  25 d:  6\n",
      "t:  25 d:  7\n",
      "t:  25 d:  8\n",
      "t:  25 d:  9\n",
      "t:  26 d:  0\n",
      "t:  26 d:  1\n",
      "t:  26 d:  2\n",
      "t:  26 d:  3\n",
      "t:  26 d:  4\n",
      "t:  26 d:  5\n",
      "t:  26 d:  6\n",
      "t:  26 d:  7\n",
      "t:  26 d:  8\n",
      "t:  26 d:  9\n",
      "t:  27 d:  0\n",
      "t:  27 d:  1\n",
      "t:  27 d:  2\n",
      "t:  27 d:  3\n",
      "t:  27 d:  4\n",
      "t:  27 d:  5\n",
      "t:  27 d:  6\n",
      "t:  27 d:  7\n",
      "t:  27 d:  8\n",
      "t:  27 d:  9\n",
      "t:  28 d:  0\n",
      "t:  28 d:  1\n",
      "t:  28 d:  2\n",
      "t:  28 d:  3\n",
      "t:  28 d:  4\n",
      "t:  28 d:  5\n",
      "t:  28 d:  6\n",
      "t:  28 d:  7\n",
      "t:  28 d:  8\n",
      "t:  28 d:  9\n",
      "t:  29 d:  0\n",
      "t:  29 d:  1\n",
      "t:  29 d:  2\n",
      "t:  29 d:  3\n",
      "t:  29 d:  4\n",
      "t:  29 d:  5\n",
      "t:  29 d:  6\n",
      "t:  29 d:  7\n",
      "t:  29 d:  8\n",
      "t:  29 d:  9\n",
      "t:  30 d:  0\n",
      "t:  30 d:  1\n",
      "t:  30 d:  2\n",
      "t:  30 d:  3\n",
      "t:  30 d:  4\n",
      "t:  30 d:  5\n",
      "t:  30 d:  6\n",
      "t:  30 d:  7\n",
      "t:  30 d:  8\n",
      "t:  30 d:  9\n",
      "t:  31 d:  0\n",
      "t:  31 d:  1\n",
      "t:  31 d:  2\n",
      "t:  31 d:  3\n",
      "t:  31 d:  4\n",
      "t:  31 d:  5\n",
      "t:  31 d:  6\n",
      "t:  31 d:  7\n",
      "t:  31 d:  8\n",
      "t:  31 d:  9\n",
      "t:  32 d:  0\n",
      "t:  32 d:  1\n",
      "t:  32 d:  2\n",
      "t:  32 d:  3\n",
      "t:  32 d:  4\n",
      "t:  32 d:  5\n",
      "t:  32 d:  6\n",
      "t:  32 d:  7\n",
      "t:  32 d:  8\n",
      "t:  32 d:  9\n",
      "t:  33 d:  0\n",
      "t:  33 d:  1\n",
      "t:  33 d:  2\n",
      "t:  33 d:  3\n",
      "t:  33 d:  4\n",
      "t:  33 d:  5\n",
      "t:  33 d:  6\n",
      "t:  33 d:  7\n",
      "t:  33 d:  8\n",
      "t:  33 d:  9\n",
      "t:  34 d:  0\n",
      "t:  34 d:  1\n",
      "t:  34 d:  2\n",
      "t:  34 d:  3\n",
      "t:  34 d:  4\n",
      "t:  34 d:  5\n",
      "t:  34 d:  6\n",
      "t:  34 d:  7\n",
      "t:  34 d:  8\n",
      "t:  34 d:  9\n",
      "t:  35 d:  0\n",
      "t:  35 d:  1\n",
      "t:  35 d:  2\n",
      "t:  35 d:  3\n",
      "t:  35 d:  4\n",
      "t:  35 d:  5\n",
      "t:  35 d:  6\n",
      "t:  35 d:  7\n",
      "t:  35 d:  8\n",
      "t:  35 d:  9\n",
      "t:  36 d:  0\n",
      "t:  36 d:  1\n",
      "t:  36 d:  2\n",
      "t:  36 d:  3\n",
      "t:  36 d:  4\n",
      "t:  36 d:  5\n",
      "t:  36 d:  6\n",
      "t:  36 d:  7\n",
      "t:  36 d:  8\n",
      "t:  36 d:  9\n",
      "t:  37 d:  0\n",
      "t:  37 d:  1\n",
      "t:  37 d:  2\n",
      "t:  37 d:  3\n",
      "t:  37 d:  4\n",
      "t:  37 d:  5\n",
      "t:  37 d:  6\n",
      "t:  37 d:  7\n",
      "t:  37 d:  8\n",
      "t:  37 d:  9\n",
      "t:  38 d:  0\n",
      "t:  38 d:  1\n",
      "t:  38 d:  2\n",
      "t:  38 d:  3\n",
      "t:  38 d:  4\n",
      "t:  38 d:  5\n",
      "t:  38 d:  6\n",
      "t:  38 d:  7\n",
      "t:  38 d:  8\n",
      "t:  38 d:  9\n",
      "t:  39 d:  0\n",
      "t:  39 d:  1\n",
      "t:  39 d:  2\n",
      "t:  39 d:  3\n",
      "t:  39 d:  4\n",
      "t:  39 d:  5\n",
      "t:  39 d:  6\n",
      "t:  39 d:  7\n",
      "t:  39 d:  8\n",
      "t:  39 d:  9\n",
      "t:  40 d:  0\n",
      "t:  40 d:  1\n",
      "t:  40 d:  2\n",
      "t:  40 d:  3\n",
      "t:  40 d:  4\n",
      "t:  40 d:  5\n",
      "t:  40 d:  6\n",
      "t:  40 d:  7\n",
      "t:  40 d:  8\n",
      "t:  40 d:  9\n",
      "t:  41 d:  0\n",
      "t:  41 d:  1\n",
      "t:  41 d:  2\n",
      "t:  41 d:  3\n",
      "t:  41 d:  4\n",
      "t:  41 d:  5\n",
      "t:  41 d:  6\n",
      "t:  41 d:  7\n",
      "t:  41 d:  8\n",
      "t:  41 d:  9\n",
      "t:  42 d:  0\n",
      "t:  42 d:  1\n",
      "t:  42 d:  2\n",
      "t:  42 d:  3\n",
      "t:  42 d:  4\n",
      "t:  42 d:  5\n",
      "t:  42 d:  6\n",
      "t:  42 d:  7\n",
      "t:  42 d:  8\n",
      "t:  42 d:  9\n",
      "t:  43 d:  0\n",
      "t:  43 d:  1\n",
      "t:  43 d:  2\n",
      "t:  43 d:  3\n",
      "t:  43 d:  4\n",
      "t:  43 d:  5\n",
      "t:  43 d:  6\n",
      "t:  43 d:  7\n",
      "t:  43 d:  8\n",
      "t:  43 d:  9\n",
      "t:  44 d:  0\n",
      "t:  44 d:  1\n",
      "t:  44 d:  2\n",
      "t:  44 d:  3\n",
      "t:  44 d:  4\n",
      "t:  44 d:  5\n",
      "t:  44 d:  6\n",
      "t:  44 d:  7\n",
      "t:  44 d:  8\n",
      "t:  44 d:  9\n",
      "t:  45 d:  0\n",
      "t:  45 d:  1\n",
      "t:  45 d:  2\n",
      "t:  45 d:  3\n",
      "t:  45 d:  4\n",
      "t:  45 d:  5\n",
      "t:  45 d:  6\n",
      "t:  45 d:  7\n",
      "t:  45 d:  8\n",
      "t:  45 d:  9\n",
      "t:  46 d:  0\n",
      "t:  46 d:  1\n",
      "t:  46 d:  2\n",
      "t:  46 d:  3\n",
      "t:  46 d:  4\n",
      "t:  46 d:  5\n",
      "t:  46 d:  6\n",
      "t:  46 d:  7\n",
      "t:  46 d:  8\n",
      "t:  46 d:  9\n",
      "t:  47 d:  0\n",
      "t:  47 d:  1\n",
      "t:  47 d:  2\n",
      "t:  47 d:  3\n",
      "t:  47 d:  4\n",
      "t:  47 d:  5\n",
      "t:  47 d:  6\n",
      "t:  47 d:  7\n",
      "t:  47 d:  8\n",
      "t:  47 d:  9\n",
      "t:  48 d:  0\n",
      "t:  48 d:  1\n",
      "t:  48 d:  2\n",
      "t:  48 d:  3\n",
      "t:  48 d:  4\n",
      "t:  48 d:  5\n",
      "t:  48 d:  6\n",
      "t:  48 d:  7\n",
      "t:  48 d:  8\n",
      "t:  48 d:  9\n",
      "t:  49 d:  0\n",
      "t:  49 d:  1\n",
      "t:  49 d:  2\n",
      "t:  49 d:  3\n",
      "t:  49 d:  4\n",
      "t:  49 d:  5\n",
      "t:  49 d:  6\n",
      "t:  49 d:  7\n",
      "t:  49 d:  8\n",
      "t:  49 d:  9\n",
      "t:  50 d:  0\n",
      "t:  50 d:  1\n",
      "t:  50 d:  2\n",
      "t:  50 d:  3\n",
      "t:  50 d:  4\n",
      "t:  50 d:  5\n",
      "t:  50 d:  6\n",
      "t:  50 d:  7\n",
      "t:  50 d:  8\n",
      "t:  50 d:  9\n",
      "t:  51 d:  0\n",
      "t:  51 d:  1\n",
      "t:  51 d:  2\n",
      "t:  51 d:  3\n",
      "t:  51 d:  4\n",
      "t:  51 d:  5\n",
      "t:  51 d:  6\n",
      "t:  51 d:  7\n",
      "t:  51 d:  8\n",
      "t:  51 d:  9\n",
      "t:  52 d:  0\n",
      "t:  52 d:  1\n",
      "t:  52 d:  2\n",
      "t:  52 d:  3\n",
      "t:  52 d:  4\n",
      "t:  52 d:  5\n",
      "t:  52 d:  6\n",
      "t:  52 d:  7\n",
      "t:  52 d:  8\n",
      "t:  52 d:  9\n",
      "t:  53 d:  0\n",
      "t:  53 d:  1\n",
      "t:  53 d:  2\n",
      "t:  53 d:  3\n",
      "t:  53 d:  4\n",
      "t:  53 d:  5\n",
      "t:  53 d:  6\n",
      "t:  53 d:  7\n",
      "t:  53 d:  8\n",
      "t:  53 d:  9\n",
      "t:  54 d:  0\n",
      "t:  54 d:  1\n",
      "t:  54 d:  2\n",
      "t:  54 d:  3\n",
      "t:  54 d:  4\n",
      "t:  54 d:  5\n",
      "t:  54 d:  6\n",
      "t:  54 d:  7\n",
      "t:  54 d:  8\n",
      "t:  54 d:  9\n",
      "t:  55 d:  0\n",
      "t:  55 d:  1\n",
      "t:  55 d:  2\n",
      "t:  55 d:  3\n",
      "t:  55 d:  4\n",
      "t:  55 d:  5\n",
      "t:  55 d:  6\n",
      "t:  55 d:  7\n",
      "t:  55 d:  8\n",
      "t:  55 d:  9\n",
      "t:  56 d:  0\n",
      "t:  56 d:  1\n",
      "t:  56 d:  2\n",
      "t:  56 d:  3\n",
      "t:  56 d:  4\n",
      "t:  56 d:  5\n",
      "t:  56 d:  6\n",
      "t:  56 d:  7\n",
      "t:  56 d:  8\n",
      "t:  56 d:  9\n",
      "t:  57 d:  0\n",
      "t:  57 d:  1\n",
      "t:  57 d:  2\n",
      "t:  57 d:  3\n",
      "t:  57 d:  4\n",
      "t:  57 d:  5\n",
      "t:  57 d:  6\n",
      "t:  57 d:  7\n",
      "t:  57 d:  8\n",
      "t:  57 d:  9\n",
      "t:  58 d:  0\n",
      "t:  58 d:  1\n",
      "t:  58 d:  2\n",
      "t:  58 d:  3\n",
      "t:  58 d:  4\n",
      "t:  58 d:  5\n",
      "t:  58 d:  6\n",
      "t:  58 d:  7\n",
      "t:  58 d:  8\n",
      "t:  58 d:  9\n",
      "t:  59 d:  0\n",
      "t:  59 d:  1\n",
      "t:  59 d:  2\n",
      "t:  59 d:  3\n",
      "t:  59 d:  4\n",
      "t:  59 d:  5\n",
      "t:  59 d:  6\n",
      "t:  59 d:  7\n",
      "t:  59 d:  8\n",
      "t:  59 d:  9\n",
      "Simulation number:  2 \n",
      "\n",
      "t:  0 d:  0\n",
      "t:  0 d:  1\n",
      "t:  0 d:  2\n",
      "t:  0 d:  3\n",
      "t:  0 d:  4\n",
      "t:  0 d:  5\n",
      "t:  0 d:  6\n",
      "t:  0 d:  7\n",
      "t:  0 d:  8\n",
      "t:  0 d:  9\n",
      "t:  1 d:  0\n",
      "t:  1 d:  1\n",
      "t:  1 d:  2\n",
      "t:  1 d:  3\n",
      "t:  1 d:  4\n",
      "t:  1 d:  5\n",
      "t:  1 d:  6\n",
      "t:  1 d:  7\n",
      "t:  1 d:  8\n",
      "t:  1 d:  9\n",
      "t:  2 d:  0\n",
      "t:  2 d:  1\n",
      "t:  2 d:  2\n",
      "t:  2 d:  3\n",
      "t:  2 d:  4\n",
      "t:  2 d:  5\n",
      "t:  2 d:  6\n",
      "t:  2 d:  7\n",
      "t:  2 d:  8\n",
      "t:  2 d:  9\n",
      "t:  3 d:  0\n",
      "t:  3 d:  1\n",
      "t:  3 d:  2\n",
      "t:  3 d:  3\n",
      "t:  3 d:  4\n",
      "t:  3 d:  5\n",
      "t:  3 d:  6\n",
      "t:  3 d:  7\n",
      "t:  3 d:  8\n",
      "t:  3 d:  9\n",
      "t:  4 d:  0\n",
      "t:  4 d:  1\n",
      "t:  4 d:  2\n",
      "t:  4 d:  3\n",
      "t:  4 d:  4\n",
      "t:  4 d:  5\n",
      "t:  4 d:  6\n",
      "t:  4 d:  7\n",
      "t:  4 d:  8\n",
      "t:  4 d:  9\n",
      "t:  5 d:  0\n",
      "t:  5 d:  1\n",
      "t:  5 d:  2\n",
      "t:  5 d:  3\n",
      "t:  5 d:  4\n",
      "t:  5 d:  5\n",
      "t:  5 d:  6\n",
      "t:  5 d:  7\n",
      "t:  5 d:  8\n",
      "t:  5 d:  9\n",
      "t:  6 d:  0\n",
      "t:  6 d:  1\n",
      "t:  6 d:  2\n",
      "t:  6 d:  3\n",
      "t:  6 d:  4\n",
      "t:  6 d:  5\n",
      "t:  6 d:  6\n",
      "t:  6 d:  7\n",
      "t:  6 d:  8\n",
      "t:  6 d:  9\n",
      "t:  7 d:  0\n",
      "t:  7 d:  1\n",
      "t:  7 d:  2\n",
      "t:  7 d:  3\n",
      "t:  7 d:  4\n",
      "t:  7 d:  5\n",
      "t:  7 d:  6\n",
      "t:  7 d:  7\n",
      "t:  7 d:  8\n",
      "t:  7 d:  9\n",
      "t:  8 d:  0\n",
      "t:  8 d:  1\n",
      "t:  8 d:  2\n",
      "t:  8 d:  3\n",
      "t:  8 d:  4\n",
      "t:  8 d:  5\n",
      "t:  8 d:  6\n",
      "t:  8 d:  7\n",
      "t:  8 d:  8\n",
      "t:  8 d:  9\n",
      "t:  9 d:  0\n",
      "t:  9 d:  1\n",
      "t:  9 d:  2\n",
      "t:  9 d:  3\n",
      "t:  9 d:  4\n",
      "t:  9 d:  5\n",
      "t:  9 d:  6\n",
      "t:  9 d:  7\n",
      "t:  9 d:  8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m bYpast \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdigitize(Y_B[simIdx][t\u001b[38;5;241m-\u001b[39md,:], bins\u001b[38;5;241m=\u001b[39mbin_edges, right\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m bX \u001b[38;5;241m=\u001b[39m (bX_sig \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m n_binsX \u001b[38;5;241m+\u001b[39m bX_noise\n\u001b[0;32m---> 25\u001b[0m te_B[simIdx][t][d], dfi_B[simIdx][t][d], fit_B[simIdx][t][d] \u001b[38;5;241m=\u001b[39m compute_FIT_TE_DFI(S, bX, bYt, bYpast)\n",
      "Cell \u001b[0;32mIn[14], line 55\u001b[0m, in \u001b[0;36mcompute_FIT_TE_DFI\u001b[0;34m(feature, X, Y, hY, xtrap)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Compute Joint, SUI, FIT and TE for the 2 divided version\u001b[39;00m\n\u001b[1;32m     49\u001b[0m joint2 \u001b[38;5;241m=\u001b[39m [[\n\u001b[1;32m     50\u001b[0m     get_joint_prob_distr(\u001b[38;5;241m*\u001b[39m[data2_tot[ch,row, :, i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m)])\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(data2_tot\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])]\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(data2_tot\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     53\u001b[0m ]\n\u001b[0;32m---> 55\u001b[0m SUI_2 \u001b[38;5;241m=\u001b[39m [[get_SUI(joint2[ch][i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(joint2))]\n\u001b[1;32m     57\u001b[0m FIT2[xIdx] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mmin(SUI_2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     58\u001b[0m TE2[xIdx] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([compute_TE(joint2[\u001b[38;5;241m0\u001b[39m][i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m)])\n",
      "Cell \u001b[0;32mIn[14], line 55\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Compute Joint, SUI, FIT and TE for the 2 divided version\u001b[39;00m\n\u001b[1;32m     49\u001b[0m joint2 \u001b[38;5;241m=\u001b[39m [[\n\u001b[1;32m     50\u001b[0m     get_joint_prob_distr(\u001b[38;5;241m*\u001b[39m[data2_tot[ch,row, :, i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m)])\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(data2_tot\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])]\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(data2_tot\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     53\u001b[0m ]\n\u001b[0;32m---> 55\u001b[0m SUI_2 \u001b[38;5;241m=\u001b[39m [[get_SUI(joint2[ch][i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(joint2))]\n\u001b[1;32m     57\u001b[0m FIT2[xIdx] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mmin(SUI_2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     58\u001b[0m TE2[xIdx] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([compute_TE(joint2[\u001b[38;5;241m0\u001b[39m][i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m)])\n",
      "Cell \u001b[0;32mIn[14], line 55\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Compute Joint, SUI, FIT and TE for the 2 divided version\u001b[39;00m\n\u001b[1;32m     49\u001b[0m joint2 \u001b[38;5;241m=\u001b[39m [[\n\u001b[1;32m     50\u001b[0m     get_joint_prob_distr(\u001b[38;5;241m*\u001b[39m[data2_tot[ch,row, :, i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m)])\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(data2_tot\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])]\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(data2_tot\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     53\u001b[0m ]\n\u001b[0;32m---> 55\u001b[0m SUI_2 \u001b[38;5;241m=\u001b[39m [[get_SUI(joint2[ch][i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(joint2))]\n\u001b[1;32m     57\u001b[0m FIT2[xIdx] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mmin(SUI_2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     58\u001b[0m TE2[xIdx] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean([compute_TE(joint2[\u001b[38;5;241m0\u001b[39m][i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m)])\n",
      "Cell \u001b[0;32mIn[10], line 30\u001b[0m, in \u001b[0;36mget_SUI\u001b[0;34m(joint_prob_distr)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(dim_y_pres):\n\u001b[1;32m     29\u001b[0m     psy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(joint_prob_distr[:, y, :, s]) \u001b[38;5;241m/\u001b[39m (np\u001b[38;5;241m.\u001b[39msum(joint_prob_distr[:, y, :, :]) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mfinfo(\u001b[38;5;28mfloat\u001b[39m)\u001b[38;5;241m.\u001b[39meps)\n\u001b[0;32m---> 30\u001b[0m     pys \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(joint_prob_distr[:, y, :, s]) \u001b[38;5;241m/\u001b[39m (np\u001b[38;5;241m.\u001b[39msum(joint_prob_distr[:, :, :, s]) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mfinfo(\u001b[38;5;28mfloat\u001b[39m)\u001b[38;5;241m.\u001b[39meps)\n\u001b[1;32m     32\u001b[0m     spec_surprise_y[s] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pys \u001b[38;5;241m*\u001b[39m (np\u001b[38;5;241m.\u001b[39mlog2(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(ps \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mfinfo(\u001b[38;5;28mfloat\u001b[39m)\u001b[38;5;241m.\u001b[39meps)) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mlog2(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(psy \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mfinfo(\u001b[38;5;28mfloat\u001b[39m)\u001b[38;5;241m.\u001b[39meps)))\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# info provided by y past\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ZanCA/lib/python3.11/site-packages/numpy/core/fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2310\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _wrapreduction(a, np\u001b[38;5;241m.\u001b[39madd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m, axis, dtype, out, keepdims\u001b[38;5;241m=\u001b[39mkeepdims,\n\u001b[1;32m   2314\u001b[0m                       initial\u001b[38;5;241m=\u001b[39minitial, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "File \u001b[0;32m~/miniconda3/envs/ZanCA/lib/python3.11/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ufunc\u001b[38;5;241m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for simIdx in range(simReps):\n",
    "    print('Simulation number: ', simIdx, '\\n')\n",
    "\n",
    "    # Loop over time and delays\n",
    "\n",
    "    for t in range(simLen):\n",
    "        for d in range(delay_max):\n",
    "            print(\"t: \",t,\"d: \",d)\n",
    "\n",
    "            # Discretize Neural Activity\n",
    "            _, bin_edges = pd.cut(X_noise_B[simIdx][t-d,:], n_binsX, retbins=True)\n",
    "            bX_noise = np.digitize(X_noise_B[simIdx][t-d, :], bins=bin_edges, right=True)\n",
    "\n",
    "            _, bin_edges = pd.cut(X_signal_B[simIdx][t-d,:], n_binsX, retbins=True)\n",
    "            bX_sig = np.digitize(X_signal_B[simIdx][t-d,:], bins=bin_edges, right=True)\n",
    "\n",
    "            _, bin_edges = pd.cut(Y_B[simIdx][t,:], n_binsY, retbins=True)\n",
    "            bYt = np.digitize(Y_B[simIdx][t,:], bins=bin_edges, right=True)\n",
    "\n",
    "            _, bin_edges = pd.cut(Y_B[simIdx][t-d,:], n_binsY, retbins=True)\n",
    "            bYpast = np.digitize(Y_B[simIdx][t-d,:], bins=bin_edges, right=True)\n",
    "\n",
    "            bX = (bX_sig - 1) * n_binsX + bX_noise\n",
    "\n",
    "            te_B[simIdx][t][d], dfi_B[simIdx][t][d], fit_B[simIdx][t][d] = compute_FIT_TE_DFI(S, bX, bYt, bYpast)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
